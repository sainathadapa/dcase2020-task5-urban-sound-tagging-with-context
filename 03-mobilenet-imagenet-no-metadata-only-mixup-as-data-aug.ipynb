{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import torchvision.models\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f208dc13950>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://pytorch.org/docs/stable/notes/randomness.html\n",
    "\n",
    "seed = 20200701\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_hparams = {\n",
    "    'slno': 3,\n",
    "    'weights': 'imagenet',\n",
    "    'dataaug': 'mixup',\n",
    "    'comments': 'no-metadata'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "this_filename = f\"{this_hparams['slno']}-{this_hparams['weights']}-{this_hparams['dataaug']}-{this_hparams['comments']}\"\n",
    "this_log_dir = f\"./tfboard_out/{this_filename}\"\n",
    "shutil.rmtree(this_log_dir, ignore_errors=True)\n",
    "tbwriter = SummaryWriter(this_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3-imagenet-mixup-no-metadata'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "this_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df, unknown_to_known):\n",
    "    df = df.reset_index()\n",
    "    df['slno'] = df.assign(slno=1).groupby('audio_filename')['slno'].cumsum()\n",
    "    df.set_index(['audio_filename', 'slno'], inplace=True)\n",
    "\n",
    "    df_unknown = df.copy().loc[:, list(unknown_to_known.keys())]\n",
    "    df.drop(columns=list(unknown_to_known.keys()), inplace=True)\n",
    "\n",
    "    y_mask = df.copy()\n",
    "    y_mask.loc[:, :] = 1\n",
    "    for unknown, known in unknown_to_known.items():\n",
    "        y_mask.loc[\n",
    "            df_unknown[unknown] > 0.5,\n",
    "            known\n",
    "        ] = 0\n",
    "\n",
    "    df = df.swaplevel(i=1, j=0, axis=0).sort_index()\n",
    "\n",
    "    y_mask = y_mask.swaplevel(i=1, j=0, axis=0).sort_index()\n",
    "\n",
    "    y = np.concatenate([\n",
    "        df.loc[[1], :].values[..., np.newaxis],\n",
    "        df.loc[[2], :].values[..., np.newaxis],\n",
    "        df.loc[[3], :].values[..., np.newaxis]\n",
    "    ], axis=2)\n",
    "\n",
    "    y_mask = np.concatenate([\n",
    "        y_mask.loc[[1], :].values[..., np.newaxis],\n",
    "        y_mask.loc[[2], :].values[..., np.newaxis],\n",
    "        y_mask.loc[[3], :].values[..., np.newaxis]\n",
    "    ], axis=2)\n",
    "\n",
    "    X = np.concatenate([\n",
    "        np.expand_dims(np.load('./data/logmelspec/{}.npy'.format(x)).T[:635, :], axis=0)\n",
    "        for x in df.loc[[1], :].reset_index(1).audio_filename.tolist()])\n",
    "    X = np.expand_dims(X, axis=1)\n",
    "\n",
    "    return X, y, y_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/metadata.pkl', 'rb') as f:\n",
    "    metadata = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_to_known = (\n",
    "    pd.merge(metadata['taxonomy_df'].loc[lambda x: x.fine_id == 'X', ['fine', 'coarse']],\n",
    "             metadata['taxonomy_df'].loc[lambda x: x.fine_id != 'X', ['fine', 'coarse']],\n",
    "             on='coarse', how='inner')\n",
    "    .drop(columns='coarse')\n",
    "    .groupby('fine_x')['fine_y']\n",
    "    .apply(lambda x: list(x)).to_dict())\n",
    "known_labels = metadata['taxonomy_df'].loc[lambda x: x.fine_id != 'X'].fine.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([metadata['coarse_train'], metadata['fine_train']], axis=1, sort=True)\n",
    "valid_df = pd.concat([metadata['coarse_valid'], metadata['fine_valid']], axis=1, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y, train_y_mask = prepare_data(train_df, unknown_to_known)\n",
    "valid_X, valid_y, valid_y_mask = prepare_data(valid_df, unknown_to_known)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13538, 1, 635, 128)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(13538, 31, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(13538, 31, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(4308, 1, 635, 128)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(4308, 31, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(4308, 31, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape\n",
    "train_y.shape\n",
    "train_y_mask.shape\n",
    "valid_X.shape\n",
    "valid_y.shape\n",
    "valid_y_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_means = train_X.reshape(-1, 128).mean(axis=0).reshape(1, 1, 1, -1)\n",
    "channel_stds = train_X.reshape(-1, 128).std(axis=0).reshape(1, 1, 1, -1)\n",
    "train_X = (train_X - channel_means) / channel_stds\n",
    "valid_X = (valid_X - channel_means) / channel_stds\n",
    "#np.save('data/channel_means.npy', channel_means)\n",
    "#np.save('data/channel_stds.npy', channel_stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "997"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the PyTorch datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDataset(Dataset):\n",
    "\n",
    "    def __init__(self, X, y, weights, transform=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.weights = weights\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.X[idx, ...]\n",
    "        return sample, self.y[idx, ...], self.weights[idx, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = AudioDataset(torch.Tensor(train_X),\n",
    "                             torch.Tensor(train_y),\n",
    "                             torch.Tensor(train_y_mask),\n",
    "                             None)\n",
    "valid_dataset = AudioDataset(torch.Tensor(valid_X),\n",
    "                             torch.Tensor(valid_y),\n",
    "                             torch.Tensor(valid_y_mask),\n",
    "                             None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = DataLoader(valid_dataset, 128, shuffle=False,\n",
    "                        num_workers=2, drop_last=False, pin_memory=True)\n",
    "train_loader_1 = DataLoader(train_dataset, 128, shuffle=True,\n",
    "                            num_workers=2, drop_last=True, pin_memory=True)\n",
    "train_loader_2 = DataLoader(train_dataset, 128, shuffle=True,\n",
    "                            num_workers=2, drop_last=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "cuda = True\n",
    "device = torch.device('cuda:0' if cuda else 'cpu')\n",
    "print('Device: ', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.bw2col = nn.Sequential(\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.Conv2d(1, 10, 1, padding=0), nn.ReLU(),\n",
    "            nn.Conv2d(10, 3, 1, padding=0), nn.ReLU())\n",
    "\n",
    "        self.mv2 = torchvision.models.mobilenet_v2(pretrained=True)\n",
    "\n",
    "        self.final1 = nn.BatchNorm1d(1280)\n",
    "        self.final2 = nn.Linear(1280, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bw2col(x)\n",
    "        x = self.mv2.features(x)\n",
    "        x = x.max(dim=-1)[0].max(dim=-1)[0]\n",
    "        x = self.final1(x)\n",
    "        x = self.final2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /home/sainatha/.cache/torch/checkpoints/mobilenet_v2-b0353104.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70d17efbfa2c42cf9d61ebb17bb12c1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14212972.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = Model(31).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (bw2col): Sequential(\n",
       "    (0): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Conv2d(1, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(10, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (4): ReLU()\n",
       "  )\n",
       "  (mv2): MobileNetV2(\n",
       "    (features): Sequential(\n",
       "      (0): ConvBNReLU(\n",
       "        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNReLU(\n",
       "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNReLU(\n",
       "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (4): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNReLU(\n",
       "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (5): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNReLU(\n",
       "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (6): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNReLU(\n",
       "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (7): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNReLU(\n",
       "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (8): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNReLU(\n",
       "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (9): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNReLU(\n",
       "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (10): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNReLU(\n",
       "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (11): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNReLU(\n",
       "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (12): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNReLU(\n",
       "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (13): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNReLU(\n",
       "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (14): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNReLU(\n",
       "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (15): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNReLU(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (16): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNReLU(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (17): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNReLU(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (18): ConvBNReLU(\n",
       "        (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (classifier): Sequential(\n",
       "      (0): Dropout(p=0.2, inplace=False)\n",
       "      (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (final1): BatchNorm1d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (final2): Linear(in_features=1280, out_features=31, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam([model.final2.bias], lr=1, amsgrad=True)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, verbose=True)\n",
    "criterion = nn.BCEWithLogitsLoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "0.21785320483502887 0.20556739673894994\n",
      "Epoch:  1\n",
      "0.20093894529910314 0.20350358328398535\n"
     ]
    }
   ],
   "source": [
    "num_bias_training = 2\n",
    "train_loss_hist = []\n",
    "valid_loss_hist = []\n",
    "lowest_val_loss = np.inf\n",
    "epochs_without_new_lowest = 0\n",
    "train_batch_slno=0\n",
    "\n",
    "for i in range(num_bias_training):\n",
    "    print('Epoch: ', i)\n",
    "\n",
    "    this_epoch_train_loss = 0\n",
    "    for i1, i2 in zip(train_loader_1, train_loader_2):\n",
    "\n",
    "        # mixup the inputs ---------\n",
    "        alpha = 1\n",
    "        mixup_vals = np.random.beta(alpha, alpha, i1[0].shape[0])\n",
    "\n",
    "        lam = torch.Tensor(mixup_vals.reshape(mixup_vals.shape[0], 1, 1, 1))\n",
    "        inputs = (lam * i1[0]) + ((1 - lam) * i2[0])\n",
    "\n",
    "        lam = torch.Tensor(mixup_vals.reshape(mixup_vals.shape[0], 1, 1))\n",
    "        labels = (lam * i1[1]) + ((1 - lam) * i2[1])\n",
    "        masks = (lam * i1[2]) + ((1 - lam) * i2[2])\n",
    "        # mixup ends ----------\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        masks = masks.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with torch.set_grad_enabled(True):\n",
    "            model = model.train()\n",
    "            outputs = model(inputs)\n",
    "            # calculate loss for each set of annotations\n",
    "            loss_0 = criterion(outputs, labels[:, :, 0]) * masks[:, :, 0]\n",
    "            loss_1 = criterion(outputs, labels[:, :, 1]) * masks[:, :, 1]\n",
    "            loss_2 = criterion(outputs, labels[:, :, 2]) * masks[:, :, 2]\n",
    "            loss = (loss_0.sum() + loss_1.sum() + loss_2.sum()) / masks.sum()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            this_epoch_train_loss += loss.detach().cpu().numpy()\n",
    "            tbwriter.add_scalar('Batch/Loss/Train',\n",
    "                                loss.detach().cpu().numpy(),\n",
    "                                train_batch_slno)\n",
    "            train_batch_slno += 1\n",
    "\n",
    "    this_epoch_valid_loss = 0\n",
    "    for inputs, labels, masks in val_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        masks = masks.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with torch.set_grad_enabled(False):\n",
    "            model = model.eval()\n",
    "            outputs = model(inputs)\n",
    "            loss_0 = criterion(outputs, labels[:, :, 0]) * masks[:, :, 0]\n",
    "            loss_1 = criterion(outputs, labels[:, :, 1]) * masks[:, :, 1]\n",
    "            loss_2 = criterion(outputs, labels[:, :, 2]) * masks[:, :, 2]\n",
    "            loss = (loss_0.sum() + loss_1.sum() + loss_2.sum()) / masks.sum()\n",
    "            this_epoch_valid_loss += loss.detach().cpu().numpy()\n",
    "\n",
    "    this_epoch_train_loss /= len(train_loader_1)\n",
    "    this_epoch_valid_loss /= len(val_loader)\n",
    "\n",
    "    train_loss_hist.append(this_epoch_train_loss)\n",
    "    valid_loss_hist.append(this_epoch_valid_loss)\n",
    "\n",
    "    if this_epoch_valid_loss < lowest_val_loss:\n",
    "        lowest_val_loss = this_epoch_valid_loss\n",
    "        torch.save(model.state_dict(), f\"./models/{this_filename}\")\n",
    "        epochs_without_new_lowest = 0\n",
    "    else:\n",
    "        epochs_without_new_lowest += 1\n",
    "\n",
    "    if epochs_without_new_lowest >= 25:\n",
    "        break\n",
    "\n",
    "    print(this_epoch_train_loss, this_epoch_valid_loss)\n",
    "    tbwriter.add_scalar('Epoch/Loss/Train', this_epoch_train_loss, i)\n",
    "    tbwriter.add_scalar('Epoch/Loss/Valid', this_epoch_valid_loss, i)\n",
    "    tbwriter.add_scalar('Epoch/lr', optimizer.param_groups[0]['lr'], i)\n",
    "    tbwriter.flush()\n",
    "    \n",
    "    scheduler.step(this_epoch_valid_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.0005, amsgrad=True)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, verbose=True)\n",
    "criterion = nn.BCEWithLogitsLoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2\n",
      "0.16329760622410547 0.14214822036378524\n",
      "Epoch:  3\n",
      "0.15234272082646688 0.13571913759498036\n",
      "Epoch:  4\n",
      "0.14919736073130652 0.13196867923526204\n",
      "Epoch:  5\n",
      "0.14722455952848706 0.12969396372928338\n",
      "Epoch:  6\n",
      "0.14604881334872472 0.12969286958960927\n",
      "Epoch:  7\n",
      "0.14454617074557713 0.1284529908615\n",
      "Epoch:  8\n",
      "0.14330151634556906 0.12774469177512562\n",
      "Epoch:  9\n",
      "0.14285596651690347 0.13091381288626613\n",
      "Epoch:  10\n",
      "0.1413956881988616 0.1273222118616104\n",
      "Epoch:  11\n",
      "0.14119129691805157 0.12793038193793857\n",
      "Epoch:  12\n",
      "0.1406666887657983 0.12557562331066413\n",
      "Epoch:  13\n",
      "0.1393088398944764 0.12855974015067606\n",
      "Epoch:  14\n",
      "0.13858249187469482 0.12666697712505565\n",
      "Epoch:  15\n",
      "0.1373979294583911 0.12806978230090701\n",
      "Epoch:  16\n",
      "0.13731895841303327 0.13136000887436025\n",
      "Epoch:  17\n",
      "0.1368964501789638 0.12848596252939282\n",
      "Epoch:  18\n",
      "0.13630751101743607 0.12832988667137482\n",
      "Epoch    17: reducing learning rate of group 0 to 5.0000e-05.\n",
      "Epoch:  19\n",
      "0.13339849696272896 0.1252669946235769\n",
      "Epoch:  20\n",
      "0.13166460813510986 0.12559309974312782\n",
      "Epoch:  21\n",
      "0.1307208457163402 0.125766103320262\n",
      "Epoch:  22\n",
      "0.12977206792150225 0.12563024176394239\n",
      "Epoch:  23\n",
      "0.13056051979462305 0.12638171718401067\n",
      "Epoch:  24\n",
      "0.12958703410057795 0.12627498323426528\n",
      "Epoch:  25\n",
      "0.12884387232008435 0.12669414610547178\n",
      "Epoch    24: reducing learning rate of group 0 to 5.0000e-06.\n",
      "Epoch:  26\n",
      "0.12857956176712398 0.12664427257636013\n",
      "Epoch:  27\n",
      "0.12856002002954484 0.12655363626339855\n",
      "Epoch:  28\n",
      "0.12837994056088584 0.12671277321436825\n",
      "Epoch:  29\n",
      "0.1288344144821167 0.1267608292400837\n",
      "Epoch:  30\n",
      "0.12849481730234055 0.12685462175046697\n",
      "Epoch:  31\n",
      "0.12873134570462363 0.1265883408486843\n",
      "Epoch    30: reducing learning rate of group 0 to 5.0000e-07.\n",
      "Epoch:  32\n",
      "0.12835624814033508 0.1265547100235434\n",
      "Epoch:  33\n",
      "0.12805702707597189 0.12696166292709463\n",
      "Epoch:  34\n",
      "0.12860082395019987 0.1266584492781583\n",
      "Epoch:  35\n",
      "0.1283025834532011 0.12668729683055596\n",
      "Epoch:  36\n",
      "0.12839486847321194 0.12688513209714608\n",
      "Epoch:  37\n",
      "0.1283471786550113 0.12661943803815282\n",
      "Epoch    36: reducing learning rate of group 0 to 5.0000e-08.\n",
      "Epoch:  38\n",
      "0.12824760952166148 0.12665250809753642\n",
      "Epoch:  39\n",
      "0.1284377789923123 0.1267728251131142\n",
      "Epoch:  40\n",
      "0.12871625551155635 0.12670874376507366\n",
      "Epoch:  41\n",
      "0.1283668488264084 0.12662777940140052\n",
      "Epoch:  42\n",
      "0.1287425575511796 0.12687333103488474\n",
      "Epoch:  43\n",
      "0.12823183366230556 0.1267950089977068\n",
      "Epoch    42: reducing learning rate of group 0 to 5.0000e-09.\n",
      "Epoch:  44\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "for i in range(num_bias_training, epochs):\n",
    "    print('Epoch: ', i)\n",
    "\n",
    "    this_epoch_train_loss = 0\n",
    "    for i1, i2 in zip(train_loader_1, train_loader_2):\n",
    "\n",
    "        # mixup the inputs ---------\n",
    "        alpha = 1\n",
    "        mixup_vals = np.random.beta(alpha, alpha, i1[0].shape[0])\n",
    "\n",
    "        lam = torch.Tensor(mixup_vals.reshape(mixup_vals.shape[0], 1, 1, 1))\n",
    "        inputs = (lam * i1[0]) + ((1 - lam) * i2[0])\n",
    "\n",
    "        lam = torch.Tensor(mixup_vals.reshape(mixup_vals.shape[0], 1, 1))\n",
    "        labels = (lam * i1[1]) + ((1 - lam) * i2[1])\n",
    "        masks = (lam * i1[2]) + ((1 - lam) * i2[2])\n",
    "        # mixup ends ----------\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        masks = masks.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with torch.set_grad_enabled(True):\n",
    "            model = model.train()\n",
    "            outputs = model(inputs)\n",
    "            # calculate loss for each set of annotations\n",
    "            loss_0 = criterion(outputs, labels[:, :, 0]) * masks[:, :, 0]\n",
    "            loss_1 = criterion(outputs, labels[:, :, 1]) * masks[:, :, 1]\n",
    "            loss_2 = criterion(outputs, labels[:, :, 2]) * masks[:, :, 2]\n",
    "            loss = (loss_0.sum() + loss_1.sum() + loss_2.sum()) / masks.sum()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            this_epoch_train_loss += loss.detach().cpu().numpy()\n",
    "            tbwriter.add_scalar('Batch/Loss/Train',\n",
    "                                loss.detach().cpu().numpy(),\n",
    "                                train_batch_slno)\n",
    "            train_batch_slno += 1\n",
    "\n",
    "    this_epoch_valid_loss = 0\n",
    "    for inputs, labels, masks in val_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        masks = masks.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with torch.set_grad_enabled(False):\n",
    "            model = model.eval()\n",
    "            outputs = model(inputs)\n",
    "            loss_0 = criterion(outputs, labels[:, :, 0]) * masks[:, :, 0]\n",
    "            loss_1 = criterion(outputs, labels[:, :, 1]) * masks[:, :, 1]\n",
    "            loss_2 = criterion(outputs, labels[:, :, 2]) * masks[:, :, 2]\n",
    "            loss = (loss_0.sum() + loss_1.sum() + loss_2.sum()) / masks.sum()\n",
    "            this_epoch_valid_loss += loss.detach().cpu().numpy()\n",
    "\n",
    "    this_epoch_train_loss /= len(train_loader_1)\n",
    "    this_epoch_valid_loss /= len(val_loader)\n",
    "\n",
    "    train_loss_hist.append(this_epoch_train_loss)\n",
    "    valid_loss_hist.append(this_epoch_valid_loss)\n",
    "\n",
    "    if this_epoch_valid_loss < lowest_val_loss:\n",
    "        lowest_val_loss = this_epoch_valid_loss\n",
    "        torch.save(model.state_dict(), f\"./models/{this_filename}\")\n",
    "        epochs_without_new_lowest = 0\n",
    "    else:\n",
    "        epochs_without_new_lowest += 1\n",
    "\n",
    "    if epochs_without_new_lowest >= 25:\n",
    "        break\n",
    "\n",
    "    print(this_epoch_train_loss, this_epoch_valid_loss)\n",
    "    tbwriter.add_scalar('Epoch/Loss/Train', this_epoch_train_loss, i)\n",
    "    tbwriter.add_scalar('Epoch/Loss/Valid', this_epoch_valid_loss, i)\n",
    "    tbwriter.add_scalar('Epoch/lr', optimizer.param_groups[0]['lr'], i)\n",
    "    tbwriter.flush()\n",
    "    \n",
    "    scheduler.step(this_epoch_valid_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\n",
    "    f\"./models/{this_filename}\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_metrics = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_epoch_valid_loss = 0\n",
    "val_preds = []\n",
    "for inputs, labels, masks in val_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        masks = masks.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with torch.set_grad_enabled(False):\n",
    "            model = model.eval()\n",
    "            outputs = model(inputs)\n",
    "            loss_0 = criterion(outputs, labels[:, :, 0]) * masks[:, :, 0]\n",
    "            loss_1 = criterion(outputs, labels[:, :, 1]) * masks[:, :, 1]\n",
    "            loss_2 = criterion(outputs, labels[:, :, 2]) * masks[:, :, 2]\n",
    "            loss = (loss_0.sum() + loss_1.sum() + loss_2.sum()) / masks.sum()\n",
    "            this_epoch_valid_loss += loss.detach().cpu().numpy()\n",
    "            val_preds.append(outputs.detach().cpu().numpy())\n",
    "this_epoch_valid_loss /= len(val_loader)\n",
    "val_preds = np.concatenate(val_preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1252669946235769, (4308, 31))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "this_epoch_valid_loss, val_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_metrics['valid_loss'] = this_epoch_valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nodataaug_dataset = AudioDataset(torch.Tensor(train_X),\n",
    "                                       torch.Tensor(train_y),\n",
    "                                       torch.Tensor(train_y_mask),\n",
    "                                       None)\n",
    "train_nodataaug_loader = DataLoader(train_nodataaug_dataset, 64, shuffle=False)\n",
    "\n",
    "this_epoch_train_nodataaug_loss = 0\n",
    "train_preds = []\n",
    "for inputs, labels, masks in train_nodataaug_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        masks = masks.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with torch.set_grad_enabled(False):\n",
    "            model = model.eval()\n",
    "            outputs = model(inputs)\n",
    "            loss_0 = criterion(outputs, labels[:, :, 0]) * masks[:, :, 0]\n",
    "            loss_1 = criterion(outputs, labels[:, :, 1]) * masks[:, :, 1]\n",
    "            loss_2 = criterion(outputs, labels[:, :, 2]) * masks[:, :, 2]\n",
    "            loss = (loss_0.sum() + loss_1.sum() + loss_2.sum()) / masks.sum()\n",
    "            this_epoch_train_nodataaug_loss += loss.detach().cpu().numpy()\n",
    "            train_preds.append(outputs.detach().cpu().numpy())\n",
    "this_epoch_train_nodataaug_loss /= len(train_nodataaug_loader)\n",
    "train_preds = np.concatenate(train_preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.09543192713468704, (13538, 31))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "this_epoch_train_nodataaug_loss, train_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_metrics['train_loss'] = this_epoch_train_nodataaug_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_cols = ['1_engine', '2_machinery-impact', '3_non-machinery-impact',\n",
    "            '4_powered-saw', '5_alert-signal', '6_music', '7_human-voice', '8_dog',\n",
    "            '1-1_small-sounding-engine', '1-2_medium-sounding-engine',\n",
    "            '1-3_large-sounding-engine', '2-1_rock-drill', '2-2_jackhammer',\n",
    "            '2-3_hoe-ram', '2-4_pile-driver', '3-1_non-machinery-impact',\n",
    "            '4-1_chainsaw', '4-2_small-medium-rotating-saw',\n",
    "            '4-3_large-rotating-saw', '5-1_car-horn', '5-2_car-alarm', '5-3_siren',\n",
    "            '5-4_reverse-beeper', '6-1_stationary-music', '6-2_mobile-music',\n",
    "            '6-3_ice-cream-truck', '7-1_person-or-small-group-talking',\n",
    "            '7-2_person-or-small-group-shouting', '7-3_large-crowd',\n",
    "            '7-4_amplified-speech', '8-1_dog-barking-whining']\n",
    "cols_for_out = [\n",
    "    \"audio_filename\", \"1-1_small-sounding-engine\",\n",
    "    \"1-2_medium-sounding-engine\", \"1-3_large-sounding-engine\",\n",
    "    \"2-1_rock-drill\",\n",
    "    \"2-2_jackhammer\", \"2-3_hoe-ram\", \"2-4_pile-driver\",\n",
    "    \"3-1_non-machinery-impact\",\n",
    "    \"4-1_chainsaw\", \"4-2_small-medium-rotating-saw\",\n",
    "    \"4-3_large-rotating-saw\",\n",
    "    \"5-1_car-horn\", \"5-2_car-alarm\", \"5-3_siren\", \"5-4_reverse-beeper\",\n",
    "    \"6-1_stationary-music\",\n",
    "    \"6-2_mobile-music\", \"6-3_ice-cream-truck\",\n",
    "    \"7-1_person-or-small-group-talking\",\n",
    "    \"7-2_person-or-small-group-shouting\", \"7-3_large-crowd\",\n",
    "    \"7-4_amplified-speech\",\n",
    "    \"8-1_dog-barking-whining\", \"1_engine\", \"2_machinery-impact\",\n",
    "    \"3_non-machinery-impact\", \"4_powered-saw\", \"5_alert-signal\",\n",
    "    \"6_music\", \"7_human-voice\", \"8_dog\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.DataFrame((1 / (1 + np.exp(-val_preds))), columns = our_cols)\n",
    "val_df['audio_filename'] = pd.Series(\n",
    "    sorted(set(metadata['coarse_valid'].index.tolist())),\n",
    "    index=val_df.index)\n",
    "val_df = val_df.loc[:, cols_for_out]\n",
    "val_df = val_df.loc[lambda x: x.audio_filename.isin(\n",
    "    metadata['coarse_valid_gt'].index.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.to_csv('/tmp/val_subm.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./baseline_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import evaluate, macro_averaged_auprc, micro_averaged_auprc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sainatha/dcase2020-task5-urban-sound-tagging-with-context/.env/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3331: DtypeWarning: Columns (47,51,52,53,58,63,67,69) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "df_dict = evaluate(\n",
    "    '/tmp/val_subm.csv',\n",
    "    './data/annotations.csv',\n",
    "    './data/dcase-ust-taxonomy.yaml',\n",
    "    'coarse'\n",
    ")\n",
    "micro_auprc, eval_df = micro_averaged_auprc(df_dict, return_df=True)\n",
    "macro_auprc, class_auprc = macro_averaged_auprc(df_dict, return_classwise=True)\n",
    "thresh_0pt5_idx = (eval_df['threshold'] >= 0.5).to_numpy().nonzero()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8742317441875453, 0.7216638342670603, 0.6957928802588996)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{1: 0.8797384623277033,\n",
       " 2: 0.663108008386833,\n",
       " 3: 0.607555335529371,\n",
       " 4: 0.6851990800005863,\n",
       " 5: 0.9475740149559019,\n",
       " 6: 0.6434922683461373,\n",
       " 7: 0.974676211706815,\n",
       " 8: 0.3719672928831345}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "micro_auprc, macro_auprc, eval_df['F'][thresh_0pt5_idx]\n",
    "class_auprc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_metrics['valid_coarse_micro_auprc'] = micro_auprc\n",
    "this_metrics['valid_coarse_macro_auprc'] = macro_auprc\n",
    "this_metrics['valid_coarse_f1'] = eval_df['F'][thresh_0pt5_idx]\n",
    "for k, v in class_auprc.items():\n",
    "    this_metrics[f\"valid_coarse_auprc_class_{k}\"] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./baseline_code/metrics.py:609: UserWarning: Column not found: 1-X_engine-of-uncertain-size\n",
      "  warnings.warn(\"Column not found: \" + f)\n",
      "./baseline_code/metrics.py:609: UserWarning: Column not found: 2-X_other-unknown-impact-machinery\n",
      "  warnings.warn(\"Column not found: \" + f)\n",
      "./baseline_code/metrics.py:609: UserWarning: Column not found: 4-X_other-unknown-powered-saw\n",
      "  warnings.warn(\"Column not found: \" + f)\n",
      "./baseline_code/metrics.py:609: UserWarning: Column not found: 5-X_other-unknown-alert-signal\n",
      "  warnings.warn(\"Column not found: \" + f)\n",
      "./baseline_code/metrics.py:609: UserWarning: Column not found: 6-X_music-from-uncertain-source\n",
      "  warnings.warn(\"Column not found: \" + f)\n",
      "./baseline_code/metrics.py:609: UserWarning: Column not found: 7-X_other-unknown-human-voice\n",
      "  warnings.warn(\"Column not found: \" + f)\n"
     ]
    }
   ],
   "source": [
    "df_dict = evaluate(\n",
    "    '/tmp/val_subm.csv',\n",
    "    './data/annotations.csv',\n",
    "    './data/dcase-ust-taxonomy.yaml',\n",
    "    'fine'\n",
    ")\n",
    "micro_auprc, eval_df = micro_averaged_auprc(df_dict, return_df=True)\n",
    "macro_auprc, class_auprc = macro_averaged_auprc(df_dict, return_classwise=True)\n",
    "thresh_0pt5_idx = (eval_df['threshold'] >= 0.5).to_numpy().nonzero()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7936232730923559, 0.6315361196972802, 0.5495798319327732)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{1: 0.7403933118937053,\n",
       " 2: 0.5324374514523025,\n",
       " 3: 0.6284266693525574,\n",
       " 4: 0.5272418225893118,\n",
       " 5: 0.9188892945788473,\n",
       " 6: 0.3941725081218622,\n",
       " 7: 0.9190032806991948,\n",
       " 8: 0.39172461889046045}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "micro_auprc, macro_auprc, eval_df['F'][thresh_0pt5_idx]\n",
    "class_auprc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_metrics['valid_fine_micro_auprc'] = micro_auprc\n",
    "this_metrics['valid_fine_macro_auprc'] = macro_auprc\n",
    "this_metrics['valid_fine_f1'] = eval_df['F'][thresh_0pt5_idx]\n",
    "for k, v in class_auprc.items():\n",
    "    this_metrics[f\"valid_fine_auprc_class_{k}\"] = v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nodataaug_df = pd.DataFrame((1 / (1 + np.exp(-train_preds))), columns = our_cols)\n",
    "train_nodataaug_df['audio_filename'] = pd.Series(\n",
    "    sorted(set(metadata['coarse_train'].index.tolist())),\n",
    "    index=train_nodataaug_df.index)\n",
    "train_nodataaug_df = train_nodataaug_df.loc[:, cols_for_out]\n",
    "train_nodataaug_df = train_nodataaug_df.loc[lambda x: x.audio_filename.isin(\n",
    "    metadata['coarse_train_gt'].index.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nodataaug_df.to_csv('/tmp/train_nodataaug.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = evaluate(\n",
    "    '/tmp/train_nodataaug.csv',\n",
    "    './data/annotations.csv',\n",
    "    './data/dcase-ust-taxonomy.yaml',\n",
    "    'coarse',\n",
    "    True\n",
    ")\n",
    "micro_auprc, eval_df = micro_averaged_auprc(df_dict, return_df=True)\n",
    "macro_auprc, class_auprc = macro_averaged_auprc(df_dict, return_classwise=True)\n",
    "thresh_0pt5_idx = (eval_df['threshold'] >= 0.5).to_numpy().nonzero()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9294507704223223, 0.812371241172598, 0.7626262626262627)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{1: 0.9549314487817404,\n",
       " 2: 0.6994265372759887,\n",
       " 3: 0.6162542228748469,\n",
       " 4: 0.6331766917293233,\n",
       " 5: 0.9459630849646757,\n",
       " 6: 0.7273706896551724,\n",
       " 7: 0.9776508255276073,\n",
       " 8: 0.9441964285714286}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "micro_auprc, macro_auprc, eval_df['F'][thresh_0pt5_idx]\n",
    "class_auprc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_metrics['train_coarse_micro_auprc'] = micro_auprc\n",
    "this_metrics['train_coarse_macro_auprc'] = macro_auprc\n",
    "this_metrics['train_coarse_f1'] = eval_df['F'][thresh_0pt5_idx]\n",
    "for k, v in class_auprc.items():\n",
    "    this_metrics[f\"train_coarse_auprc_class_{k}\"] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = evaluate(\n",
    "    '/tmp/train_nodataaug.csv',\n",
    "    './data/annotations.csv',\n",
    "    './data/dcase-ust-taxonomy.yaml',\n",
    "    'fine',\n",
    "    True\n",
    ")\n",
    "micro_auprc, eval_df = micro_averaged_auprc(df_dict, return_df=True)\n",
    "macro_auprc, class_auprc = macro_averaged_auprc(df_dict, return_classwise=True)\n",
    "thresh_0pt5_idx = (eval_df['threshold'] >= 0.5).to_numpy().nonzero()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8328900308747694, 0.736663051872674, 0.5994694960212201)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{1: 0.7350498862800546,\n",
       " 2: 0.7469488844488845,\n",
       " 3: 0.5659175176892195,\n",
       " 4: 0.42927902221494657,\n",
       " 5: 0.9153042427411014,\n",
       " 6: 0.6488224637681159,\n",
       " 7: 0.9061695899572966,\n",
       " 8: 0.9458128078817734}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "micro_auprc, macro_auprc, eval_df['F'][thresh_0pt5_idx]\n",
    "class_auprc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_metrics['train_fine_micro_auprc'] = micro_auprc\n",
    "this_metrics['train_fine_macro_auprc'] = macro_auprc\n",
    "this_metrics['train_fine_f1'] = eval_df['F'][thresh_0pt5_idx]\n",
    "for k, v in class_auprc.items():\n",
    "    this_metrics[f\"train_fine_auprc_class_{k}\"] = v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_metrics = {\n",
    "    f'hparams/{k}': v\n",
    "    for k, v in this_metrics.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbwriter.add_hparams(hparam_dict=this_hparams, metric_dict=this_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbwriter.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "255.188px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
