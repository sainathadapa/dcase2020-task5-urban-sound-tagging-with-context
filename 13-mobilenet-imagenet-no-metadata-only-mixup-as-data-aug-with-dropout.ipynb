{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import torchvision.models\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f752a674890>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://pytorch.org/docs/stable/notes/randomness.html\n",
    "\n",
    "seed = 20200701\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_hparams = {\n",
    "    'slno': 13,\n",
    "    'weights': 'imagenet',\n",
    "    'dataaug': 'mixup',\n",
    "    'comments': 'no-metadata'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "this_filename = f\"{this_hparams['slno']}-{this_hparams['weights']}-{this_hparams['dataaug']}-{this_hparams['comments']}\"\n",
    "this_log_dir = f\"./tfboard_out/{this_filename}\"\n",
    "shutil.rmtree(this_log_dir, ignore_errors=True)\n",
    "tbwriter = SummaryWriter(this_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'13-imagenet-mixup-no-metadata'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "this_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df, unknown_to_known):\n",
    "    df = df.reset_index()\n",
    "    df['slno'] = df.assign(slno=1).groupby('audio_filename')['slno'].cumsum()\n",
    "    df.set_index(['audio_filename', 'slno'], inplace=True)\n",
    "\n",
    "    df_unknown = df.copy().loc[:, list(unknown_to_known.keys())]\n",
    "    df.drop(columns=list(unknown_to_known.keys()), inplace=True)\n",
    "\n",
    "    y_mask = df.copy()\n",
    "    y_mask.loc[:, :] = 1\n",
    "    for unknown, known in unknown_to_known.items():\n",
    "        y_mask.loc[\n",
    "            df_unknown[unknown] > 0.5,\n",
    "            known\n",
    "        ] = 0\n",
    "\n",
    "    df = df.swaplevel(i=1, j=0, axis=0).sort_index()\n",
    "\n",
    "    y_mask = y_mask.swaplevel(i=1, j=0, axis=0).sort_index()\n",
    "\n",
    "    y = np.concatenate([\n",
    "        df.loc[[1], :].values[..., np.newaxis],\n",
    "        df.loc[[2], :].values[..., np.newaxis],\n",
    "        df.loc[[3], :].values[..., np.newaxis]\n",
    "    ], axis=2)\n",
    "\n",
    "    y_mask = np.concatenate([\n",
    "        y_mask.loc[[1], :].values[..., np.newaxis],\n",
    "        y_mask.loc[[2], :].values[..., np.newaxis],\n",
    "        y_mask.loc[[3], :].values[..., np.newaxis]\n",
    "    ], axis=2)\n",
    "\n",
    "    X = np.concatenate([\n",
    "        np.expand_dims(np.load('./data/logmelspec/{}.npy'.format(x)).T[:635, :], axis=0)\n",
    "        for x in df.loc[[1], :].reset_index(1).audio_filename.tolist()])\n",
    "    X = np.expand_dims(X, axis=1)\n",
    "\n",
    "    return X, y, y_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/metadata.pkl', 'rb') as f:\n",
    "    metadata = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_to_known = (\n",
    "    pd.merge(metadata['taxonomy_df'].loc[lambda x: x.fine_id == 'X', ['fine', 'coarse']],\n",
    "             metadata['taxonomy_df'].loc[lambda x: x.fine_id != 'X', ['fine', 'coarse']],\n",
    "             on='coarse', how='inner')\n",
    "    .drop(columns='coarse')\n",
    "    .groupby('fine_x')['fine_y']\n",
    "    .apply(lambda x: list(x)).to_dict())\n",
    "known_labels = metadata['taxonomy_df'].loc[lambda x: x.fine_id != 'X'].fine.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([metadata['coarse_train'], metadata['fine_train']], axis=1, sort=True)\n",
    "valid_df = pd.concat([metadata['coarse_valid'], metadata['fine_valid']], axis=1, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y, train_y_mask = prepare_data(train_df, unknown_to_known)\n",
    "valid_X, valid_y, valid_y_mask = prepare_data(valid_df, unknown_to_known)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13538, 1, 635, 128)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(13538, 31, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(13538, 31, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(4308, 1, 635, 128)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(4308, 31, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(4308, 31, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape\n",
    "train_y.shape\n",
    "train_y_mask.shape\n",
    "valid_X.shape\n",
    "valid_y.shape\n",
    "valid_y_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_means = train_X.reshape(-1, 128).mean(axis=0).reshape(1, 1, 1, -1)\n",
    "channel_stds = train_X.reshape(-1, 128).std(axis=0).reshape(1, 1, 1, -1)\n",
    "train_X = (train_X - channel_means) / channel_stds\n",
    "valid_X = (valid_X - channel_means) / channel_stds\n",
    "#np.save('data/channel_means.npy', channel_means)\n",
    "#np.save('data/channel_stds.npy', channel_stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the PyTorch datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDataset(Dataset):\n",
    "\n",
    "    def __init__(self, X, y, weights, transform=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.weights = weights\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.X[idx, ...]\n",
    "        return sample, self.y[idx, ...], self.weights[idx, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = AudioDataset(torch.Tensor(train_X),\n",
    "                             torch.Tensor(train_y),\n",
    "                             torch.Tensor(train_y_mask),\n",
    "                             None)\n",
    "valid_dataset = AudioDataset(torch.Tensor(valid_X),\n",
    "                             torch.Tensor(valid_y),\n",
    "                             torch.Tensor(valid_y_mask),\n",
    "                             None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = DataLoader(valid_dataset, 128, shuffle=False,\n",
    "                        num_workers=2, drop_last=False, pin_memory=True)\n",
    "train_loader_1 = DataLoader(train_dataset, 128, shuffle=True,\n",
    "                            num_workers=2, drop_last=True, pin_memory=True)\n",
    "train_loader_2 = DataLoader(train_dataset, 128, shuffle=True,\n",
    "                            num_workers=2, drop_last=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "cuda = True\n",
    "device = torch.device('cuda:0' if cuda else 'cpu')\n",
    "print('Device: ', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.bw2col = nn.Sequential(\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.Conv2d(1, 10, 1, padding=0), nn.ReLU(),\n",
    "            nn.Conv2d(10, 3, 1, padding=0), nn.ReLU())\n",
    "\n",
    "        self.mv2 = torchvision.models.mobilenet_v2(pretrained=True)\n",
    "\n",
    "        self.final1 = nn.BatchNorm1d(1280)\n",
    "        self.dp = nn.Dropout(0.95)\n",
    "        self.final2 = nn.Linear(1280, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bw2col(x)\n",
    "        x = self.mv2.features(x)\n",
    "        x = x.max(dim=-1)[0].max(dim=-1)[0]\n",
    "        x = self.final1(x)\n",
    "        x = self.dp(x)\n",
    "        x = self.final2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(31).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (bw2col): Sequential(\n",
       "    (0): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Conv2d(1, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(10, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (4): ReLU()\n",
       "  )\n",
       "  (mv2): MobileNetV2(\n",
       "    (features): Sequential(\n",
       "      (0): ConvBNReLU(\n",
       "        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNReLU(\n",
       "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNReLU(\n",
       "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (4): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNReLU(\n",
       "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (5): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNReLU(\n",
       "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (6): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNReLU(\n",
       "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (7): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNReLU(\n",
       "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (8): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNReLU(\n",
       "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (9): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNReLU(\n",
       "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (10): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNReLU(\n",
       "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (11): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNReLU(\n",
       "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (12): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNReLU(\n",
       "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (13): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNReLU(\n",
       "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (14): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNReLU(\n",
       "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (15): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNReLU(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (16): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNReLU(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (17): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNReLU(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (18): ConvBNReLU(\n",
       "        (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (classifier): Sequential(\n",
       "      (0): Dropout(p=0.2, inplace=False)\n",
       "      (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (final1): BatchNorm1d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dp): Dropout(p=0.95, inplace=False)\n",
       "  (final2): Linear(in_features=1280, out_features=31, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam([model.final2.bias], lr=1, amsgrad=True)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, verbose=True)\n",
    "criterion = nn.BCEWithLogitsLoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "0.3565492059503283 0.2564506784957998\n",
      "Epoch:  1\n",
      "0.3259027574743543 0.24209601914181428\n"
     ]
    }
   ],
   "source": [
    "num_bias_training = 2\n",
    "train_loss_hist = []\n",
    "valid_loss_hist = []\n",
    "lowest_val_loss = np.inf\n",
    "epochs_without_new_lowest = 0\n",
    "train_batch_slno=0\n",
    "\n",
    "for i in range(num_bias_training):\n",
    "    print('Epoch: ', i)\n",
    "\n",
    "    this_epoch_train_loss = 0\n",
    "    for i1, i2 in zip(train_loader_1, train_loader_2):\n",
    "\n",
    "        # mixup the inputs ---------\n",
    "        alpha = 1\n",
    "        mixup_vals = np.random.beta(alpha, alpha, i1[0].shape[0])\n",
    "\n",
    "        lam = torch.Tensor(mixup_vals.reshape(mixup_vals.shape[0], 1, 1, 1))\n",
    "        inputs = (lam * i1[0]) + ((1 - lam) * i2[0])\n",
    "\n",
    "        lam = torch.Tensor(mixup_vals.reshape(mixup_vals.shape[0], 1, 1))\n",
    "        labels = (lam * i1[1]) + ((1 - lam) * i2[1])\n",
    "        masks = (lam * i1[2]) + ((1 - lam) * i2[2])\n",
    "        # mixup ends ----------\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        masks = masks.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with torch.set_grad_enabled(True):\n",
    "            model = model.train()\n",
    "            outputs = model(inputs)\n",
    "            # calculate loss for each set of annotations\n",
    "            loss_0 = criterion(outputs, labels[:, :, 0]) * masks[:, :, 0]\n",
    "            loss_1 = criterion(outputs, labels[:, :, 1]) * masks[:, :, 1]\n",
    "            loss_2 = criterion(outputs, labels[:, :, 2]) * masks[:, :, 2]\n",
    "            loss = (loss_0.sum() + loss_1.sum() + loss_2.sum()) / masks.sum()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            this_epoch_train_loss += loss.detach().cpu().numpy()\n",
    "            tbwriter.add_scalar('Batch/Loss/Train',\n",
    "                                loss.detach().cpu().numpy(),\n",
    "                                train_batch_slno)\n",
    "            train_batch_slno += 1\n",
    "\n",
    "    this_epoch_valid_loss = 0\n",
    "    for inputs, labels, masks in val_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        masks = masks.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with torch.set_grad_enabled(False):\n",
    "            model = model.eval()\n",
    "            outputs = model(inputs)\n",
    "            loss_0 = criterion(outputs, labels[:, :, 0]) * masks[:, :, 0]\n",
    "            loss_1 = criterion(outputs, labels[:, :, 1]) * masks[:, :, 1]\n",
    "            loss_2 = criterion(outputs, labels[:, :, 2]) * masks[:, :, 2]\n",
    "            loss = (loss_0.sum() + loss_1.sum() + loss_2.sum()) / masks.sum()\n",
    "            this_epoch_valid_loss += loss.detach().cpu().numpy()\n",
    "\n",
    "    this_epoch_train_loss /= len(train_loader_1)\n",
    "    this_epoch_valid_loss /= len(val_loader)\n",
    "\n",
    "    train_loss_hist.append(this_epoch_train_loss)\n",
    "    valid_loss_hist.append(this_epoch_valid_loss)\n",
    "\n",
    "    if this_epoch_valid_loss < lowest_val_loss:\n",
    "        lowest_val_loss = this_epoch_valid_loss\n",
    "        torch.save(model.state_dict(), f\"./models/{this_filename}\")\n",
    "        epochs_without_new_lowest = 0\n",
    "    else:\n",
    "        epochs_without_new_lowest += 1\n",
    "\n",
    "    if epochs_without_new_lowest >= 25:\n",
    "        break\n",
    "\n",
    "    print(this_epoch_train_loss, this_epoch_valid_loss)\n",
    "    tbwriter.add_scalar('Epoch/Loss/Train', this_epoch_train_loss, i)\n",
    "    tbwriter.add_scalar('Epoch/Loss/Valid', this_epoch_valid_loss, i)\n",
    "    tbwriter.add_scalar('Epoch/lr', optimizer.param_groups[0]['lr'], i)\n",
    "    tbwriter.flush()\n",
    "    \n",
    "    scheduler.step(this_epoch_valid_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.0005, amsgrad=True)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, verbose=True)\n",
    "criterion = nn.BCEWithLogitsLoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2\n",
      "0.2588634222745895 0.1731887350187582\n",
      "Epoch:  3\n",
      "0.20234930046967098 0.1572729690986521\n",
      "Epoch:  4\n",
      "0.18472141126791636 0.14948608989224715\n",
      "Epoch:  5\n",
      "0.17744301287900835 0.14542458162588232\n",
      "Epoch:  6\n",
      "0.17350628262474424 0.14165434854872086\n",
      "Epoch:  7\n",
      "0.17060679949465252 0.1421971257556887\n",
      "Epoch:  8\n",
      "0.1678878263348625 0.137423927512239\n",
      "Epoch:  9\n",
      "0.1671331402801332 0.14095869156367638\n",
      "Epoch:  10\n",
      "0.16462313916002 0.13901601797517607\n",
      "Epoch:  11\n",
      "0.1643148761420023 0.1350361759610036\n",
      "Epoch:  12\n",
      "0.16378811257226125 0.1352776326239109\n",
      "Epoch:  13\n",
      "0.1615520050128301 0.1376237306086456\n",
      "Epoch:  14\n",
      "0.16060597087655748 0.1329709460191867\n",
      "Epoch:  15\n",
      "0.15989698341914585 0.13303378991344394\n",
      "Epoch:  16\n",
      "0.15951867359025138 0.1324826573186061\n",
      "Epoch:  17\n",
      "0.15913340818314325 0.1310977127183886\n",
      "Epoch:  18\n",
      "0.15803442214216504 0.13288118251982858\n",
      "Epoch:  19\n",
      "0.15803944496881395 0.1300537985037355\n",
      "Epoch:  20\n",
      "0.1566913100935164 0.12900522197870648\n",
      "Epoch:  21\n",
      "0.15611528200762612 0.12991484714781537\n",
      "Epoch:  22\n",
      "0.15567906555675326 0.1288315239636337\n",
      "Epoch:  23\n",
      "0.15612754027048747 0.12929447280133471\n",
      "Epoch:  24\n",
      "0.15510363663945878 0.12898934413405025\n",
      "Epoch:  25\n",
      "0.15400874628907157 0.1291622948997161\n",
      "Epoch:  26\n",
      "0.15404460756551652 0.12966986701768987\n",
      "Epoch:  27\n",
      "0.1541690421955926 0.1289552443606012\n",
      "Epoch:  28\n",
      "0.1530701885620753 0.12869159066501787\n",
      "Epoch:  29\n",
      "0.1536211800007593 0.12975910590852008\n",
      "Epoch:  30\n",
      "0.1523397133463905 0.12911666228490717\n",
      "Epoch:  31\n",
      "0.15257652600606283 0.12815864712876432\n",
      "Epoch:  32\n",
      "0.1517600456873576 0.12883687304223285\n",
      "Epoch:  33\n",
      "0.15127627494789306 0.12898423939066775\n",
      "Epoch:  34\n",
      "0.15126479949269975 0.12954323234803536\n",
      "Epoch:  35\n",
      "0.15112412997654506 0.12943398689522462\n",
      "Epoch:  36\n",
      "0.15039238660108475 0.12842117863542893\n",
      "Epoch:  37\n",
      "0.1505480794679551 0.12842311184195912\n",
      "Epoch    36: reducing learning rate of group 0 to 5.0000e-05.\n",
      "Epoch:  38\n",
      "0.1486718829189028 0.1269653060418718\n",
      "Epoch:  39\n",
      "0.1479768216609955 0.1271030166569878\n",
      "Epoch:  40\n",
      "0.1478266410884403 0.12681066726937013\n",
      "Epoch:  41\n",
      "0.14708192263330733 0.12722790789078264\n",
      "Epoch:  42\n",
      "0.14726915331113907 0.12720995790818157\n",
      "Epoch:  43\n",
      "0.14589418357326872 0.1273694673881811\n",
      "Epoch:  44\n",
      "0.146295390242622 0.12684772536158562\n",
      "Epoch:  45\n",
      "0.14549675640605744 0.12649182997205677\n",
      "Epoch:  46\n",
      "0.14522643869831448 0.12699924497043386\n",
      "Epoch:  47\n",
      "0.1459235722110385 0.12709172924651818\n",
      "Epoch:  48\n",
      "0.1449952081555412 0.12698591894963207\n",
      "Epoch:  49\n",
      "0.14526627929437727 0.12701610716826775\n",
      "Epoch:  50\n",
      "0.14464377420289176 0.12681670377359672\n",
      "Epoch:  51\n",
      "0.1447344883566811 0.12719847678261645\n",
      "Epoch    50: reducing learning rate of group 0 to 5.0000e-06.\n",
      "Epoch:  52\n",
      "0.1446245068595523 0.12660641792942495\n",
      "Epoch:  53\n",
      "0.14478835335799625 0.1269267293460229\n",
      "Epoch:  54\n",
      "0.14480026804265522 0.12704945311826818\n",
      "Epoch:  55\n",
      "0.1445813563607988 0.12683889532790465\n",
      "Epoch:  56\n",
      "0.14458921537512825 0.1269716232576791\n",
      "Epoch:  57\n",
      "0.14423705779370807 0.12679510497871568\n",
      "Epoch    56: reducing learning rate of group 0 to 5.0000e-07.\n",
      "Epoch:  58\n",
      "0.14448906098093306 0.1269757659996257\n",
      "Epoch:  59\n",
      "0.14402646734600977 0.12703801319003105\n",
      "Epoch:  60\n",
      "0.14490595105148496 0.12707808285075076\n",
      "Epoch:  61\n",
      "0.14439681881950014 0.12696437055573745\n",
      "Epoch:  62\n",
      "0.14426301831290836 0.1271339446744498\n",
      "Epoch:  63\n",
      "0.14421551468826477 0.12707328226636438\n",
      "Epoch    62: reducing learning rate of group 0 to 5.0000e-08.\n",
      "Epoch:  64\n",
      "0.14419125006312417 0.12686480033923597\n",
      "Epoch:  65\n",
      "0.14438593415986925 0.1269835518563495\n",
      "Epoch:  66\n",
      "0.1443307916323344 0.12720042028847864\n",
      "Epoch:  67\n",
      "0.1446081537575949 0.12696996725657406\n",
      "Epoch:  68\n",
      "0.14409615723859695 0.1269407684312147\n",
      "Epoch:  69\n",
      "0.1443931844972429 0.12691116508315592\n",
      "Epoch    68: reducing learning rate of group 0 to 5.0000e-09.\n",
      "Epoch:  70\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "for i in range(num_bias_training, epochs):\n",
    "    print('Epoch: ', i)\n",
    "\n",
    "    this_epoch_train_loss = 0\n",
    "    for i1, i2 in zip(train_loader_1, train_loader_2):\n",
    "\n",
    "        # mixup the inputs ---------\n",
    "        alpha = 1\n",
    "        mixup_vals = np.random.beta(alpha, alpha, i1[0].shape[0])\n",
    "\n",
    "        lam = torch.Tensor(mixup_vals.reshape(mixup_vals.shape[0], 1, 1, 1))\n",
    "        inputs = (lam * i1[0]) + ((1 - lam) * i2[0])\n",
    "\n",
    "        lam = torch.Tensor(mixup_vals.reshape(mixup_vals.shape[0], 1, 1))\n",
    "        labels = (lam * i1[1]) + ((1 - lam) * i2[1])\n",
    "        masks = (lam * i1[2]) + ((1 - lam) * i2[2])\n",
    "        # mixup ends ----------\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        masks = masks.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with torch.set_grad_enabled(True):\n",
    "            model = model.train()\n",
    "            outputs = model(inputs)\n",
    "            # calculate loss for each set of annotations\n",
    "            loss_0 = criterion(outputs, labels[:, :, 0]) * masks[:, :, 0]\n",
    "            loss_1 = criterion(outputs, labels[:, :, 1]) * masks[:, :, 1]\n",
    "            loss_2 = criterion(outputs, labels[:, :, 2]) * masks[:, :, 2]\n",
    "            loss = (loss_0.sum() + loss_1.sum() + loss_2.sum()) / masks.sum()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            this_epoch_train_loss += loss.detach().cpu().numpy()\n",
    "            tbwriter.add_scalar('Batch/Loss/Train',\n",
    "                                loss.detach().cpu().numpy(),\n",
    "                                train_batch_slno)\n",
    "            train_batch_slno += 1\n",
    "\n",
    "    this_epoch_valid_loss = 0\n",
    "    for inputs, labels, masks in val_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        masks = masks.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with torch.set_grad_enabled(False):\n",
    "            model = model.eval()\n",
    "            outputs = model(inputs)\n",
    "            loss_0 = criterion(outputs, labels[:, :, 0]) * masks[:, :, 0]\n",
    "            loss_1 = criterion(outputs, labels[:, :, 1]) * masks[:, :, 1]\n",
    "            loss_2 = criterion(outputs, labels[:, :, 2]) * masks[:, :, 2]\n",
    "            loss = (loss_0.sum() + loss_1.sum() + loss_2.sum()) / masks.sum()\n",
    "            this_epoch_valid_loss += loss.detach().cpu().numpy()\n",
    "\n",
    "    this_epoch_train_loss /= len(train_loader_1)\n",
    "    this_epoch_valid_loss /= len(val_loader)\n",
    "\n",
    "    train_loss_hist.append(this_epoch_train_loss)\n",
    "    valid_loss_hist.append(this_epoch_valid_loss)\n",
    "\n",
    "    if this_epoch_valid_loss < lowest_val_loss:\n",
    "        lowest_val_loss = this_epoch_valid_loss\n",
    "        torch.save(model.state_dict(), f\"./models/{this_filename}\")\n",
    "        epochs_without_new_lowest = 0\n",
    "    else:\n",
    "        epochs_without_new_lowest += 1\n",
    "\n",
    "    if epochs_without_new_lowest >= 25:\n",
    "        break\n",
    "\n",
    "    print(this_epoch_train_loss, this_epoch_valid_loss)\n",
    "    tbwriter.add_scalar('Epoch/Loss/Train', this_epoch_train_loss, i)\n",
    "    tbwriter.add_scalar('Epoch/Loss/Valid', this_epoch_valid_loss, i)\n",
    "    tbwriter.add_scalar('Epoch/lr', optimizer.param_groups[0]['lr'], i)\n",
    "    tbwriter.flush()\n",
    "    \n",
    "    scheduler.step(this_epoch_valid_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\n",
    "    f\"./models/{this_filename}\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_metrics = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_epoch_valid_loss = 0\n",
    "val_preds = []\n",
    "for inputs, labels, masks in val_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        masks = masks.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with torch.set_grad_enabled(False):\n",
    "            model = model.eval()\n",
    "            outputs = model(inputs)\n",
    "            loss_0 = criterion(outputs, labels[:, :, 0]) * masks[:, :, 0]\n",
    "            loss_1 = criterion(outputs, labels[:, :, 1]) * masks[:, :, 1]\n",
    "            loss_2 = criterion(outputs, labels[:, :, 2]) * masks[:, :, 2]\n",
    "            loss = (loss_0.sum() + loss_1.sum() + loss_2.sum()) / masks.sum()\n",
    "            this_epoch_valid_loss += loss.detach().cpu().numpy()\n",
    "            val_preds.append(outputs.detach().cpu().numpy())\n",
    "this_epoch_valid_loss /= len(val_loader)\n",
    "val_preds = np.concatenate(val_preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.12649182997205677, (4308, 31))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "this_epoch_valid_loss, val_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_metrics['valid_loss'] = this_epoch_valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nodataaug_dataset = AudioDataset(torch.Tensor(train_X),\n",
    "                                       torch.Tensor(train_y),\n",
    "                                       torch.Tensor(train_y_mask),\n",
    "                                       None)\n",
    "train_nodataaug_loader = DataLoader(train_nodataaug_dataset, 64, shuffle=False)\n",
    "\n",
    "this_epoch_train_nodataaug_loss = 0\n",
    "train_preds = []\n",
    "for inputs, labels, masks in train_nodataaug_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        masks = masks.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with torch.set_grad_enabled(False):\n",
    "            model = model.eval()\n",
    "            outputs = model(inputs)\n",
    "            loss_0 = criterion(outputs, labels[:, :, 0]) * masks[:, :, 0]\n",
    "            loss_1 = criterion(outputs, labels[:, :, 1]) * masks[:, :, 1]\n",
    "            loss_2 = criterion(outputs, labels[:, :, 2]) * masks[:, :, 2]\n",
    "            loss = (loss_0.sum() + loss_1.sum() + loss_2.sum()) / masks.sum()\n",
    "            this_epoch_train_nodataaug_loss += loss.detach().cpu().numpy()\n",
    "            train_preds.append(outputs.detach().cpu().numpy())\n",
    "this_epoch_train_nodataaug_loss /= len(train_nodataaug_loader)\n",
    "train_preds = np.concatenate(train_preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.10567742600193564, (13538, 31))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "this_epoch_train_nodataaug_loss, train_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_metrics['train_loss'] = this_epoch_train_nodataaug_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_cols = ['1_engine', '2_machinery-impact', '3_non-machinery-impact',\n",
    "            '4_powered-saw', '5_alert-signal', '6_music', '7_human-voice', '8_dog',\n",
    "            '1-1_small-sounding-engine', '1-2_medium-sounding-engine',\n",
    "            '1-3_large-sounding-engine', '2-1_rock-drill', '2-2_jackhammer',\n",
    "            '2-3_hoe-ram', '2-4_pile-driver', '3-1_non-machinery-impact',\n",
    "            '4-1_chainsaw', '4-2_small-medium-rotating-saw',\n",
    "            '4-3_large-rotating-saw', '5-1_car-horn', '5-2_car-alarm', '5-3_siren',\n",
    "            '5-4_reverse-beeper', '6-1_stationary-music', '6-2_mobile-music',\n",
    "            '6-3_ice-cream-truck', '7-1_person-or-small-group-talking',\n",
    "            '7-2_person-or-small-group-shouting', '7-3_large-crowd',\n",
    "            '7-4_amplified-speech', '8-1_dog-barking-whining']\n",
    "cols_for_out = [\n",
    "    \"audio_filename\", \"1-1_small-sounding-engine\",\n",
    "    \"1-2_medium-sounding-engine\", \"1-3_large-sounding-engine\",\n",
    "    \"2-1_rock-drill\",\n",
    "    \"2-2_jackhammer\", \"2-3_hoe-ram\", \"2-4_pile-driver\",\n",
    "    \"3-1_non-machinery-impact\",\n",
    "    \"4-1_chainsaw\", \"4-2_small-medium-rotating-saw\",\n",
    "    \"4-3_large-rotating-saw\",\n",
    "    \"5-1_car-horn\", \"5-2_car-alarm\", \"5-3_siren\", \"5-4_reverse-beeper\",\n",
    "    \"6-1_stationary-music\",\n",
    "    \"6-2_mobile-music\", \"6-3_ice-cream-truck\",\n",
    "    \"7-1_person-or-small-group-talking\",\n",
    "    \"7-2_person-or-small-group-shouting\", \"7-3_large-crowd\",\n",
    "    \"7-4_amplified-speech\",\n",
    "    \"8-1_dog-barking-whining\", \"1_engine\", \"2_machinery-impact\",\n",
    "    \"3_non-machinery-impact\", \"4_powered-saw\", \"5_alert-signal\",\n",
    "    \"6_music\", \"7_human-voice\", \"8_dog\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.DataFrame((1 / (1 + np.exp(-val_preds))), columns = our_cols)\n",
    "val_df['audio_filename'] = pd.Series(\n",
    "    sorted(set(metadata['coarse_valid'].index.tolist())),\n",
    "    index=val_df.index)\n",
    "val_df = val_df.loc[:, cols_for_out]\n",
    "val_df = val_df.loc[lambda x: x.audio_filename.isin(\n",
    "    metadata['coarse_valid_gt'].index.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.to_csv('/tmp/val_subm.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./baseline_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import evaluate, macro_averaged_auprc, micro_averaged_auprc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sainatha/dcase2020-task5-urban-sound-tagging-with-context/.env/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3331: DtypeWarning: Columns (47,51,52,53,58,63,67,69) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "df_dict = evaluate(\n",
    "    '/tmp/val_subm.csv',\n",
    "    './data/annotations.csv',\n",
    "    './data/dcase-ust-taxonomy.yaml',\n",
    "    'coarse'\n",
    ")\n",
    "micro_auprc, eval_df = micro_averaged_auprc(df_dict, return_df=True)\n",
    "macro_auprc, class_auprc = macro_averaged_auprc(df_dict, return_classwise=True)\n",
    "thresh_0pt5_idx = (eval_df['threshold'] >= 0.5).to_numpy().nonzero()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8686645236444286, 0.7214446113632289, 0.6765432098765433)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{1: 0.8764111992766471,\n",
       " 2: 0.6982448724237262,\n",
       " 3: 0.5570097418071949,\n",
       " 4: 0.7560119651883711,\n",
       " 5: 0.9380457596387136,\n",
       " 6: 0.654429708599257,\n",
       " 7: 0.976695463480683,\n",
       " 8: 0.31470818049123805}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "micro_auprc, macro_auprc, eval_df['F'][thresh_0pt5_idx]\n",
    "class_auprc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_metrics['valid_coarse_micro_auprc'] = micro_auprc\n",
    "this_metrics['valid_coarse_macro_auprc'] = macro_auprc\n",
    "this_metrics['valid_coarse_f1'] = eval_df['F'][thresh_0pt5_idx]\n",
    "for k, v in class_auprc.items():\n",
    "    this_metrics[f\"valid_coarse_auprc_class_{k}\"] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./baseline_code/metrics.py:609: UserWarning: Column not found: 1-X_engine-of-uncertain-size\n",
      "  warnings.warn(\"Column not found: \" + f)\n",
      "./baseline_code/metrics.py:609: UserWarning: Column not found: 2-X_other-unknown-impact-machinery\n",
      "  warnings.warn(\"Column not found: \" + f)\n",
      "./baseline_code/metrics.py:609: UserWarning: Column not found: 4-X_other-unknown-powered-saw\n",
      "  warnings.warn(\"Column not found: \" + f)\n",
      "./baseline_code/metrics.py:609: UserWarning: Column not found: 5-X_other-unknown-alert-signal\n",
      "  warnings.warn(\"Column not found: \" + f)\n",
      "./baseline_code/metrics.py:609: UserWarning: Column not found: 6-X_music-from-uncertain-source\n",
      "  warnings.warn(\"Column not found: \" + f)\n",
      "./baseline_code/metrics.py:609: UserWarning: Column not found: 7-X_other-unknown-human-voice\n",
      "  warnings.warn(\"Column not found: \" + f)\n"
     ]
    }
   ],
   "source": [
    "df_dict = evaluate(\n",
    "    '/tmp/val_subm.csv',\n",
    "    './data/annotations.csv',\n",
    "    './data/dcase-ust-taxonomy.yaml',\n",
    "    'fine'\n",
    ")\n",
    "micro_auprc, eval_df = micro_averaged_auprc(df_dict, return_df=True)\n",
    "macro_auprc, class_auprc = macro_averaged_auprc(df_dict, return_classwise=True)\n",
    "thresh_0pt5_idx = (eval_df['threshold'] >= 0.5).to_numpy().nonzero()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7842398872504351, 0.6001445523788691, 0.5283018867924528)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{1: 0.7182494613385717,\n",
       " 2: 0.5040153964219461,\n",
       " 3: 0.5614860679822228,\n",
       " 4: 0.4609196458123451,\n",
       " 5: 0.9028025625599717,\n",
       " 6: 0.40756640567204205,\n",
       " 7: 0.9330372274940121,\n",
       " 8: 0.3130796517498416}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "micro_auprc, macro_auprc, eval_df['F'][thresh_0pt5_idx]\n",
    "class_auprc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_metrics['valid_fine_micro_auprc'] = micro_auprc\n",
    "this_metrics['valid_fine_macro_auprc'] = macro_auprc\n",
    "this_metrics['valid_fine_f1'] = eval_df['F'][thresh_0pt5_idx]\n",
    "for k, v in class_auprc.items():\n",
    "    this_metrics[f\"valid_fine_auprc_class_{k}\"] = v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nodataaug_df = pd.DataFrame((1 / (1 + np.exp(-train_preds))), columns = our_cols)\n",
    "train_nodataaug_df['audio_filename'] = pd.Series(\n",
    "    sorted(set(metadata['coarse_train'].index.tolist())),\n",
    "    index=train_nodataaug_df.index)\n",
    "train_nodataaug_df = train_nodataaug_df.loc[:, cols_for_out]\n",
    "train_nodataaug_df = train_nodataaug_df.loc[lambda x: x.audio_filename.isin(\n",
    "    metadata['coarse_train_gt'].index.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nodataaug_df.to_csv('/tmp/train_nodataaug.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = evaluate(\n",
    "    '/tmp/train_nodataaug.csv',\n",
    "    './data/annotations.csv',\n",
    "    './data/dcase-ust-taxonomy.yaml',\n",
    "    'coarse',\n",
    "    True\n",
    ")\n",
    "micro_auprc, eval_df = micro_averaged_auprc(df_dict, return_df=True)\n",
    "macro_auprc, class_auprc = macro_averaged_auprc(df_dict, return_classwise=True)\n",
    "thresh_0pt5_idx = (eval_df['threshold'] >= 0.5).to_numpy().nonzero()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9275287061046454, 0.8050875133247778, 0.7428571428571428)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{1: 0.9368813060072784,\n",
       " 2: 0.7713243294164347,\n",
       " 3: 0.5581926266499817,\n",
       " 4: 0.5532647907647907,\n",
       " 5: 0.9460442602627157,\n",
       " 6: 0.7611111111111111,\n",
       " 7: 0.966079484583712,\n",
       " 8: 0.9478021978021978}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "micro_auprc, macro_auprc, eval_df['F'][thresh_0pt5_idx]\n",
    "class_auprc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_metrics['train_coarse_micro_auprc'] = micro_auprc\n",
    "this_metrics['train_coarse_macro_auprc'] = macro_auprc\n",
    "this_metrics['train_coarse_f1'] = eval_df['F'][thresh_0pt5_idx]\n",
    "for k, v in class_auprc.items():\n",
    "    this_metrics[f\"train_coarse_auprc_class_{k}\"] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = evaluate(\n",
    "    '/tmp/train_nodataaug.csv',\n",
    "    './data/annotations.csv',\n",
    "    './data/dcase-ust-taxonomy.yaml',\n",
    "    'fine',\n",
    "    True\n",
    ")\n",
    "micro_auprc, eval_df = micro_averaged_auprc(df_dict, return_df=True)\n",
    "macro_auprc, class_auprc = macro_averaged_auprc(df_dict, return_classwise=True)\n",
    "thresh_0pt5_idx = (eval_df['threshold'] >= 0.5).to_numpy().nonzero()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8284110411319765, 0.7456719850195954, 0.5266106442577031)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{1: 0.7177747689095472,\n",
       " 2: 0.7659436846031049,\n",
       " 3: 0.5539935213998826,\n",
       " 4: 0.4139239232989233,\n",
       " 5: 0.9285416808478071,\n",
       " 6: 0.7708333333333334,\n",
       " 7: 0.8685521598823913,\n",
       " 8: 0.9458128078817734}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "micro_auprc, macro_auprc, eval_df['F'][thresh_0pt5_idx]\n",
    "class_auprc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_metrics['train_fine_micro_auprc'] = micro_auprc\n",
    "this_metrics['train_fine_macro_auprc'] = macro_auprc\n",
    "this_metrics['train_fine_f1'] = eval_df['F'][thresh_0pt5_idx]\n",
    "for k, v in class_auprc.items():\n",
    "    this_metrics[f\"train_fine_auprc_class_{k}\"] = v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_metrics = {\n",
    "    f'hparams/{k}': v\n",
    "    for k, v in this_metrics.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbwriter.add_hparams(hparam_dict=this_hparams, metric_dict=this_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbwriter.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "255.188px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
