{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import torchvision.models\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f23cf5c1ad0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://pytorch.org/docs/stable/notes/randomness.html\n",
    "\n",
    "seed = 20200701\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_hparams = {\n",
    "    'slno': 8,\n",
    "    'weights': 'imagenet',\n",
    "    'dataaug': 'mixup',\n",
    "    'comments': 'metadata-all'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "this_filename = f\"{this_hparams['slno']}-{this_hparams['weights']}-{this_hparams['dataaug']}-{this_hparams['comments']}\"\n",
    "this_log_dir = f\"./tfboard_out/{this_filename}\"\n",
    "shutil.rmtree(this_log_dir, ignore_errors=True)\n",
    "tbwriter = SummaryWriter(this_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8-imagenet-mixup-metadata-all'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "this_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df, unknown_to_known):\n",
    "    df = df.reset_index()\n",
    "    df['slno'] = df.assign(slno=1).groupby('audio_filename')['slno'].cumsum()\n",
    "    df.set_index(['audio_filename', 'slno'], inplace=True)\n",
    "\n",
    "    df_unknown = df.copy().loc[:, list(unknown_to_known.keys())]\n",
    "    df.drop(columns=list(unknown_to_known.keys()), inplace=True)\n",
    "\n",
    "    y_mask = df.copy()\n",
    "    y_mask.loc[:, :] = 1\n",
    "    for unknown, known in unknown_to_known.items():\n",
    "        y_mask.loc[\n",
    "            df_unknown[unknown] > 0.5,\n",
    "            known\n",
    "        ] = 0\n",
    "\n",
    "    df = df.swaplevel(i=1, j=0, axis=0).sort_index()\n",
    "\n",
    "    y_mask = y_mask.swaplevel(i=1, j=0, axis=0).sort_index()\n",
    "\n",
    "    y = np.concatenate([\n",
    "        df.loc[[1], :].values[..., np.newaxis],\n",
    "        df.loc[[2], :].values[..., np.newaxis],\n",
    "        df.loc[[3], :].values[..., np.newaxis]\n",
    "    ], axis=2)\n",
    "\n",
    "    y_mask = np.concatenate([\n",
    "        y_mask.loc[[1], :].values[..., np.newaxis],\n",
    "        y_mask.loc[[2], :].values[..., np.newaxis],\n",
    "        y_mask.loc[[3], :].values[..., np.newaxis]\n",
    "    ], axis=2)\n",
    "\n",
    "    X = np.concatenate([\n",
    "        np.expand_dims(np.load('./data/logmelspec/{}.npy'.format(x)).T[:635, :], axis=0)\n",
    "        for x in df.loc[[1], :].reset_index(1).audio_filename.tolist()])\n",
    "    X = np.expand_dims(X, axis=1)\n",
    "\n",
    "    return X, y, y_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/metadata.pkl', 'rb') as f:\n",
    "    metadata = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_to_known = (\n",
    "    pd.merge(metadata['taxonomy_df'].loc[lambda x: x.fine_id == 'X', ['fine', 'coarse']],\n",
    "             metadata['taxonomy_df'].loc[lambda x: x.fine_id != 'X', ['fine', 'coarse']],\n",
    "             on='coarse', how='inner')\n",
    "    .drop(columns='coarse')\n",
    "    .groupby('fine_x')['fine_y']\n",
    "    .apply(lambda x: list(x)).to_dict())\n",
    "known_labels = metadata['taxonomy_df'].loc[lambda x: x.fine_id != 'X'].fine.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([metadata['coarse_train'], metadata['fine_train']], axis=1, sort=True)\n",
    "valid_df = pd.concat([metadata['coarse_valid'], metadata['fine_valid']], axis=1, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y, train_y_mask = prepare_data(train_df, unknown_to_known)\n",
    "valid_X, valid_y, valid_y_mask = prepare_data(valid_df, unknown_to_known)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_select = ['borough', 'latitude', 'longitude', 'week', 'day', 'hour', 'date_slno']\n",
    "train_metadata = metadata['train_metadata'].loc[:, cols_to_select]\n",
    "valid_metadata = metadata['valid_metadata'].loc[:, cols_to_select]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in ['borough', 'day', 'hour']:\n",
    "    train_metadata[x] = train_metadata[x].astype('str')\n",
    "    valid_metadata[x] = valid_metadata[x].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata = pd.get_dummies(train_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_metadata = pd.get_dummies(valid_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_metadata['borough_4'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_metadata = valid_metadata.loc[:, train_metadata.columns.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_min = train_metadata.latitude.min()\n",
    "lat_max = train_metadata.latitude.max()\n",
    "train_metadata.latitude = (train_metadata.latitude - lat_min) / (lat_max - lat_min)\n",
    "valid_metadata.latitude = (valid_metadata.latitude - lat_min) / (lat_max - lat_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_min = train_metadata.longitude.min()\n",
    "lon_max = train_metadata.longitude.max()\n",
    "train_metadata.longitude = (train_metadata.longitude - lon_min) / (lon_max - lon_min)\n",
    "valid_metadata.longitude = (valid_metadata.longitude - lon_min) / (lon_max - lon_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "wk_min = train_metadata.week.min()\n",
    "wk_max = train_metadata.week.max()\n",
    "train_metadata.week = (train_metadata.week - wk_min) / (wk_max - wk_min)\n",
    "valid_metadata.week = (valid_metadata.week - wk_min) / (wk_max - wk_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_min = train_metadata.date_slno.min()\n",
    "dt_max = train_metadata.date_slno.max()\n",
    "train_metadata.date_slno = (train_metadata.date_slno - dt_min) / (dt_max - dt_min)\n",
    "valid_metadata.date_slno = (valid_metadata.date_slno - dt_min) / (dt_max - dt_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>week</th>\n",
       "      <th>date_slno</th>\n",
       "      <th>borough_1</th>\n",
       "      <th>borough_3</th>\n",
       "      <th>borough_4</th>\n",
       "      <th>day_0</th>\n",
       "      <th>day_1</th>\n",
       "      <th>day_2</th>\n",
       "      <th>...</th>\n",
       "      <th>hour_21</th>\n",
       "      <th>hour_22</th>\n",
       "      <th>hour_23</th>\n",
       "      <th>hour_3</th>\n",
       "      <th>hour_4</th>\n",
       "      <th>hour_5</th>\n",
       "      <th>hour_6</th>\n",
       "      <th>hour_7</th>\n",
       "      <th>hour_8</th>\n",
       "      <th>hour_9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>audio_filename</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00_000066.wav</th>\n",
       "      <td>0.41245</td>\n",
       "      <td>0.072543</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.392655</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00_000071.wav</th>\n",
       "      <td>0.41245</td>\n",
       "      <td>0.072543</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.197740</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                latitude  longitude      week  date_slno  borough_1  \\\n",
       "audio_filename                                                        \n",
       "00_000066.wav    0.41245   0.072543  0.529412   0.392655          1   \n",
       "00_000071.wav    0.41245   0.072543  0.960784   0.197740          1   \n",
       "\n",
       "                borough_3  borough_4  day_0  day_1  day_2  ...  hour_21  \\\n",
       "audio_filename                                             ...            \n",
       "00_000066.wav           0          0      0      0      1  ...        0   \n",
       "00_000071.wav           0          0      0      0      0  ...        0   \n",
       "\n",
       "                hour_22  hour_23  hour_3  hour_4  hour_5  hour_6  hour_7  \\\n",
       "audio_filename                                                             \n",
       "00_000066.wav         0        0       0       0       0       0       0   \n",
       "00_000071.wav         0        0       0       0       0       0       0   \n",
       "\n",
       "                hour_8  hour_9  \n",
       "audio_filename                  \n",
       "00_000066.wav        0       0  \n",
       "00_000071.wav        0       0  \n",
       "\n",
       "[2 rows x 38 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_metadata.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>week</th>\n",
       "      <th>date_slno</th>\n",
       "      <th>borough_1</th>\n",
       "      <th>borough_3</th>\n",
       "      <th>borough_4</th>\n",
       "      <th>day_0</th>\n",
       "      <th>day_1</th>\n",
       "      <th>day_2</th>\n",
       "      <th>...</th>\n",
       "      <th>hour_21</th>\n",
       "      <th>hour_22</th>\n",
       "      <th>hour_23</th>\n",
       "      <th>hour_3</th>\n",
       "      <th>hour_4</th>\n",
       "      <th>hour_5</th>\n",
       "      <th>hour_6</th>\n",
       "      <th>hour_7</th>\n",
       "      <th>hour_8</th>\n",
       "      <th>hour_9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>audio_filename</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01_000006.wav</th>\n",
       "      <td>0.42201</td>\n",
       "      <td>0.041071</td>\n",
       "      <td>0.313725</td>\n",
       "      <td>0.318267</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01_000038.wav</th>\n",
       "      <td>0.42201</td>\n",
       "      <td>0.041071</td>\n",
       "      <td>0.392157</td>\n",
       "      <td>0.346516</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                latitude  longitude      week  date_slno  borough_1  \\\n",
       "audio_filename                                                        \n",
       "01_000006.wav    0.42201   0.041071  0.313725   0.318267          1   \n",
       "01_000038.wav    0.42201   0.041071  0.392157   0.346516          1   \n",
       "\n",
       "                borough_3  borough_4  day_0  day_1  day_2  ...  hour_21  \\\n",
       "audio_filename                                             ...            \n",
       "01_000006.wav           0          0      1      0      0  ...        0   \n",
       "01_000038.wav           0          0      0      0      1  ...        0   \n",
       "\n",
       "                hour_22  hour_23  hour_3  hour_4  hour_5  hour_6  hour_7  \\\n",
       "audio_filename                                                             \n",
       "01_000006.wav         0        0       0       0       0       0       0   \n",
       "01_000038.wav         0        0       0       0       0       0       0   \n",
       "\n",
       "                hour_8  hour_9  \n",
       "audio_filename                  \n",
       "01_000006.wav        0       0  \n",
       "01_000038.wav        0       0  \n",
       "\n",
       "[2 rows x 38 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_metadata.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata = train_metadata.values\n",
    "valid_metadata = valid_metadata.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13538, 1, 635, 128)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(13538, 31, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(13538, 31, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(13538, 38)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(4308, 1, 635, 128)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(4308, 31, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(4308, 31, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(4308, 38)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape\n",
    "train_y.shape\n",
    "train_y_mask.shape\n",
    "train_metadata.shape\n",
    "valid_X.shape\n",
    "valid_y.shape\n",
    "valid_y_mask.shape\n",
    "valid_metadata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_means = train_X.reshape(-1, 128).mean(axis=0).reshape(1, 1, 1, -1)\n",
    "channel_stds = train_X.reshape(-1, 128).std(axis=0).reshape(1, 1, 1, -1)\n",
    "train_X = (train_X - channel_means) / channel_stds\n",
    "valid_X = (valid_X - channel_means) / channel_stds\n",
    "#np.save('data/channel_means.npy', channel_means)\n",
    "#np.save('data/channel_stds.npy', channel_stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the PyTorch datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDataset(Dataset):\n",
    "\n",
    "    def __init__(self, X, y, weights, metadata, transform=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.weights = weights\n",
    "        self.metadata = metadata\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.X[idx, ...]\n",
    "        return sample, self.y[idx, ...], self.weights[idx, ...], self.metadata[idx, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = AudioDataset(torch.Tensor(train_X),\n",
    "                             torch.Tensor(train_y),\n",
    "                             torch.Tensor(train_y_mask),\n",
    "                             torch.Tensor(train_metadata),\n",
    "                             None)\n",
    "valid_dataset = AudioDataset(torch.Tensor(valid_X),\n",
    "                             torch.Tensor(valid_y),\n",
    "                             torch.Tensor(valid_y_mask),\n",
    "                             torch.Tensor(valid_metadata),\n",
    "                             None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = DataLoader(valid_dataset, 128, shuffle=False,\n",
    "                        num_workers=2, drop_last=False, pin_memory=True)\n",
    "train_loader_1 = DataLoader(train_dataset, 128, shuffle=True,\n",
    "                            num_workers=2, drop_last=True, pin_memory=True)\n",
    "train_loader_2 = DataLoader(train_dataset, 128, shuffle=True,\n",
    "                            num_workers=2, drop_last=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "cuda = True\n",
    "device = torch.device('cuda:0' if cuda else 'cpu')\n",
    "print('Device: ', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.bw2col = nn.Sequential(\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.Conv2d(1, 10, 1, padding=0), nn.ReLU(),\n",
    "            nn.Conv2d(10, 3, 1, padding=0), nn.ReLU())\n",
    "\n",
    "        self.mv2 = torchvision.models.mobilenet_v2(pretrained=True)\n",
    "        self.mv2.classifier = None\n",
    "        \n",
    "        self.after_mv2 = nn.Sequential(\n",
    "            nn.BatchNorm1d(1280),\n",
    "            nn.Dropout(0.7),\n",
    "            nn.Linear(1280, 48),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(48),\n",
    "        )\n",
    "        \n",
    "        self.meta_seq = nn.Sequential(\n",
    "            nn.BatchNorm1d(38),\n",
    "            nn.Linear(38, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Linear(128, 16),\n",
    "            nn.BatchNorm1d(16),\n",
    "        )\n",
    "        \n",
    "        self.final_dense = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x, with_metadata=False, metadata=None):\n",
    "        \n",
    "        x = self.bw2col(x)\n",
    "        x = self.mv2.features(x)\n",
    "        x = x.max(dim=-1)[0].max(dim=-1)[0]\n",
    "        x = self.after_mv2(x)\n",
    "        \n",
    "        if not with_metadata:\n",
    "            raise('this shouldnt happen')\n",
    "        \n",
    "        meta_out = self.meta_seq(metadata)\n",
    "        \n",
    "        x = torch.cat((x, meta_out), axis=-1)\n",
    "        x = self.final_dense(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (bw2col): Sequential(\n",
       "    (0): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Conv2d(1, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(10, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (4): ReLU()\n",
       "  )\n",
       "  (mv2): MobileNetV2(\n",
       "    (features): Sequential(\n",
       "      (0): ConvBNReLU(\n",
       "        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNReLU(\n",
       "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNReLU(\n",
       "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (4): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNReLU(\n",
       "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (5): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNReLU(\n",
       "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (6): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNReLU(\n",
       "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (7): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNReLU(\n",
       "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (8): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNReLU(\n",
       "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (9): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNReLU(\n",
       "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (10): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNReLU(\n",
       "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (11): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNReLU(\n",
       "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (12): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNReLU(\n",
       "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (13): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNReLU(\n",
       "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (14): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNReLU(\n",
       "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (15): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNReLU(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (16): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNReLU(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (17): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): ConvBNReLU(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): ConvBNReLU(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (18): ConvBNReLU(\n",
       "        (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (classifier): None\n",
       "  )\n",
       "  (after_mv2): Sequential(\n",
       "    (0): BatchNorm1d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Dropout(p=0.7, inplace=False)\n",
       "    (2): Linear(in_features=1280, out_features=48, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (meta_seq): Sequential(\n",
       "    (0): BatchNorm1d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Linear(in_features=38, out_features=128, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): Linear(in_features=128, out_features=16, bias=True)\n",
       "    (5): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (final_dense): Linear(in_features=64, out_features=31, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam([model.final_dense.bias], lr=1, amsgrad=True)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, verbose=True)\n",
    "criterion = nn.BCEWithLogitsLoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "0.2169676885718391 0.19866639375686646\n",
      "Epoch:  1\n",
      "0.20116266239257086 0.20099910830750184\n"
     ]
    }
   ],
   "source": [
    "num_bias_training = 2\n",
    "train_loss_hist = []\n",
    "valid_loss_hist = []\n",
    "lowest_val_loss = np.inf\n",
    "epochs_without_new_lowest = 0\n",
    "train_batch_slno=0\n",
    "\n",
    "for i in range(num_bias_training):\n",
    "    print('Epoch: ', i)\n",
    "\n",
    "    this_epoch_train_loss = 0\n",
    "    for i1, i2 in zip(train_loader_1, train_loader_2):\n",
    "\n",
    "        # mixup the inputs ---------\n",
    "        alpha = 1\n",
    "        mixup_vals = np.random.beta(alpha, alpha, i1[0].shape[0])\n",
    "\n",
    "        lam = torch.Tensor(mixup_vals.reshape(mixup_vals.shape[0], 1, 1, 1))\n",
    "        inputs = (lam * i1[0]) + ((1 - lam) * i2[0])\n",
    "\n",
    "        lam = torch.Tensor(mixup_vals.reshape(mixup_vals.shape[0], 1, 1))\n",
    "        labels = (lam * i1[1]) + ((1 - lam) * i2[1])\n",
    "        masks = (lam * i1[2]) + ((1 - lam) * i2[2])\n",
    "        \n",
    "        lam = torch.Tensor(mixup_vals.reshape(mixup_vals.shape[0], 1))\n",
    "        meta = (lam * i1[3]) + ((1 - lam) * i2[3])\n",
    "        # mixup ends ----------\n",
    "\n",
    "        inputs = inputs.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "        masks = masks.to(device, non_blocking=True)\n",
    "        meta = meta.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with torch.set_grad_enabled(True):\n",
    "            model = model.train()\n",
    "            outputs = model(inputs, with_metadata=True, metadata=meta)\n",
    "            # calculate loss for each set of annotations\n",
    "            loss_0 = criterion(outputs, labels[:, :, 0]) * masks[:, :, 0]\n",
    "            loss_1 = criterion(outputs, labels[:, :, 1]) * masks[:, :, 1]\n",
    "            loss_2 = criterion(outputs, labels[:, :, 2]) * masks[:, :, 2]\n",
    "            loss = (loss_0.sum() + loss_1.sum() + loss_2.sum()) / masks.sum()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            this_epoch_train_loss += loss.detach().cpu().numpy()\n",
    "            tbwriter.add_scalar('Batch/Loss/Train',\n",
    "                                loss.detach().cpu().numpy(),\n",
    "                                train_batch_slno)\n",
    "            train_batch_slno += 1\n",
    "\n",
    "    this_epoch_valid_loss = 0\n",
    "    for inputs, labels, masks, meta in val_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        masks = masks.to(device)\n",
    "        meta = meta.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with torch.set_grad_enabled(False):\n",
    "            model = model.eval()\n",
    "            outputs = model(inputs, with_metadata=True, metadata=meta)\n",
    "            loss_0 = criterion(outputs, labels[:, :, 0]) * masks[:, :, 0]\n",
    "            loss_1 = criterion(outputs, labels[:, :, 1]) * masks[:, :, 1]\n",
    "            loss_2 = criterion(outputs, labels[:, :, 2]) * masks[:, :, 2]\n",
    "            loss = (loss_0.sum() + loss_1.sum() + loss_2.sum()) / masks.sum()\n",
    "            this_epoch_valid_loss += loss.detach().cpu().numpy()\n",
    "\n",
    "    this_epoch_train_loss /= len(train_loader_1)\n",
    "    this_epoch_valid_loss /= len(val_loader)\n",
    "\n",
    "    train_loss_hist.append(this_epoch_train_loss)\n",
    "    valid_loss_hist.append(this_epoch_valid_loss)\n",
    "\n",
    "    if this_epoch_valid_loss < lowest_val_loss:\n",
    "        lowest_val_loss = this_epoch_valid_loss\n",
    "        torch.save(model.state_dict(), f\"./models/{this_filename}\")\n",
    "        epochs_without_new_lowest = 0\n",
    "    else:\n",
    "        epochs_without_new_lowest += 1\n",
    "\n",
    "    if epochs_without_new_lowest >= 25:\n",
    "        break\n",
    "\n",
    "    print(this_epoch_train_loss, this_epoch_valid_loss)\n",
    "    tbwriter.add_scalar('Epoch/Loss/Train', this_epoch_train_loss, i)\n",
    "    tbwriter.add_scalar('Epoch/Loss/Valid', this_epoch_valid_loss, i)\n",
    "    tbwriter.add_scalar('Epoch/lr', optimizer.param_groups[0]['lr'], i)\n",
    "    tbwriter.flush()\n",
    "    \n",
    "    scheduler.step(this_epoch_valid_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.0005, amsgrad=True)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, verbose=True)\n",
    "criterion = nn.BCEWithLogitsLoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2\n",
      "0.17045468489329021 0.14706880182904356\n",
      "Epoch:  3\n",
      "0.15727403944446927 0.1436290125198224\n",
      "Epoch:  4\n",
      "0.15275365057445708 0.13608157897696777\n",
      "Epoch:  5\n",
      "0.150939203727813 0.13224683592424674\n",
      "Epoch:  6\n",
      "0.14906418266750518 0.13081745869096587\n",
      "Epoch:  7\n",
      "0.14783645896684555 0.13024026747135556\n",
      "Epoch:  8\n",
      "0.14625373425937835 0.12934942543506622\n",
      "Epoch:  9\n",
      "0.145275702221053 0.1282193509533125\n",
      "Epoch:  10\n",
      "0.14414949928011214 0.12729057297110558\n",
      "Epoch:  11\n",
      "0.1441092753694171 0.12715048299116247\n",
      "Epoch:  12\n",
      "0.1434506112620944 0.12656551577589092\n",
      "Epoch:  13\n",
      "0.14278551538785297 0.12712694836013458\n",
      "Epoch:  14\n",
      "0.14160769837243217 0.12728235673378496\n",
      "Epoch:  15\n",
      "0.14122980563413529 0.12749606195618124\n",
      "Epoch:  16\n",
      "0.14067870605559576 0.1288188351866077\n",
      "Epoch:  17\n",
      "0.14050089504037586 0.1283610414932756\n",
      "Epoch:  18\n",
      "0.1403930698122297 0.12838667696889708\n",
      "Epoch    17: reducing learning rate of group 0 to 5.0000e-05.\n",
      "Epoch:  19\n",
      "0.13809238303275334 0.1258260408306823\n",
      "Epoch:  20\n",
      "0.13707891546544573 0.1256669082624071\n",
      "Epoch:  21\n",
      "0.13650164902210235 0.12567627232740908\n",
      "Epoch:  22\n",
      "0.13636231053443182 0.12572489043369012\n",
      "Epoch:  23\n",
      "0.1363570084174474 0.12616317806875005\n",
      "Epoch:  24\n",
      "0.13589763286567869 0.12641176121199832\n",
      "Epoch:  25\n",
      "0.13542691071828206 0.1260271620224504\n",
      "Epoch:  26\n",
      "0.1347165501543454 0.12712337843635502\n",
      "Epoch    25: reducing learning rate of group 0 to 5.0000e-06.\n",
      "Epoch:  27\n",
      "0.13494005827676683 0.1267567951889599\n",
      "Epoch:  28\n",
      "0.1348211184853599 0.1266010677551522\n",
      "Epoch:  29\n",
      "0.13444552684114092 0.12659515002194574\n",
      "Epoch:  30\n",
      "0.13434763848781586 0.12674642661038568\n",
      "Epoch:  31\n",
      "0.1348587935169538 0.12650355696678162\n",
      "Epoch:  32\n",
      "0.1345247866142364 0.12663464511142059\n",
      "Epoch    31: reducing learning rate of group 0 to 5.0000e-07.\n",
      "Epoch:  33\n",
      "0.13437982201576232 0.1266932636499405\n",
      "Epoch:  34\n",
      "0.13478798752739315 0.12656630970099392\n",
      "Epoch:  35\n",
      "0.1343578719667026 0.1266772562966627\n",
      "Epoch:  36\n",
      "0.13412058623064133 0.12688516277600737\n",
      "Epoch:  37\n",
      "0.13468855151108333 0.12673710505752003\n",
      "Epoch:  38\n",
      "0.1345185975233714 0.12686318356324644\n",
      "Epoch    37: reducing learning rate of group 0 to 5.0000e-08.\n",
      "Epoch:  39\n",
      "0.1344162628764198 0.1267282726133571\n",
      "Epoch:  40\n",
      "0.1345804703377542 0.12666748858550014\n",
      "Epoch:  41\n",
      "0.13454336566584452 0.1266909180318608\n",
      "Epoch:  42\n",
      "0.13540485501289368 0.12662275069776704\n",
      "Epoch:  43\n",
      "0.1344904424888747 0.1266668859650107\n",
      "Epoch:  44\n",
      "0.13456271290779115 0.12699656911632595\n",
      "Epoch    43: reducing learning rate of group 0 to 5.0000e-09.\n",
      "Epoch:  45\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "for i in range(num_bias_training, epochs):\n",
    "    print('Epoch: ', i)\n",
    "\n",
    "    this_epoch_train_loss = 0\n",
    "    for i1, i2 in zip(train_loader_1, train_loader_2):\n",
    "\n",
    "        # mixup the inputs ---------\n",
    "        alpha = 1\n",
    "        mixup_vals = np.random.beta(alpha, alpha, i1[0].shape[0])\n",
    "\n",
    "        lam = torch.Tensor(mixup_vals.reshape(mixup_vals.shape[0], 1, 1, 1))\n",
    "        inputs = (lam * i1[0]) + ((1 - lam) * i2[0])\n",
    "\n",
    "        lam = torch.Tensor(mixup_vals.reshape(mixup_vals.shape[0], 1, 1))\n",
    "        labels = (lam * i1[1]) + ((1 - lam) * i2[1])\n",
    "        masks = (lam * i1[2]) + ((1 - lam) * i2[2])\n",
    "        \n",
    "        lam = torch.Tensor(mixup_vals.reshape(mixup_vals.shape[0], 1))\n",
    "        meta = (lam * i1[3]) + ((1 - lam) * i2[3])\n",
    "        # mixup ends ----------\n",
    "\n",
    "        inputs = inputs.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "        masks = masks.to(device, non_blocking=True)\n",
    "        meta = meta.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with torch.set_grad_enabled(True):\n",
    "            model = model.train()\n",
    "            outputs = model(inputs, with_metadata=True, metadata=meta)\n",
    "            # calculate loss for each set of annotations\n",
    "            loss_0 = criterion(outputs, labels[:, :, 0]) * masks[:, :, 0]\n",
    "            loss_1 = criterion(outputs, labels[:, :, 1]) * masks[:, :, 1]\n",
    "            loss_2 = criterion(outputs, labels[:, :, 2]) * masks[:, :, 2]\n",
    "            loss = (loss_0.sum() + loss_1.sum() + loss_2.sum()) / masks.sum()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            this_epoch_train_loss += loss.detach().cpu().numpy()\n",
    "            tbwriter.add_scalar('Batch/Loss/Train',\n",
    "                                loss.detach().cpu().numpy(),\n",
    "                                train_batch_slno)\n",
    "            train_batch_slno += 1\n",
    "\n",
    "    this_epoch_valid_loss = 0\n",
    "    for inputs, labels, masks, meta in val_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        masks = masks.to(device)\n",
    "        meta = meta.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with torch.set_grad_enabled(False):\n",
    "            model = model.eval()\n",
    "            outputs = model(inputs, with_metadata=True, metadata=meta)\n",
    "            loss_0 = criterion(outputs, labels[:, :, 0]) * masks[:, :, 0]\n",
    "            loss_1 = criterion(outputs, labels[:, :, 1]) * masks[:, :, 1]\n",
    "            loss_2 = criterion(outputs, labels[:, :, 2]) * masks[:, :, 2]\n",
    "            loss = (loss_0.sum() + loss_1.sum() + loss_2.sum()) / masks.sum()\n",
    "            this_epoch_valid_loss += loss.detach().cpu().numpy()\n",
    "\n",
    "    this_epoch_train_loss /= len(train_loader_1)\n",
    "    this_epoch_valid_loss /= len(val_loader)\n",
    "\n",
    "    train_loss_hist.append(this_epoch_train_loss)\n",
    "    valid_loss_hist.append(this_epoch_valid_loss)\n",
    "\n",
    "    if this_epoch_valid_loss < lowest_val_loss:\n",
    "        lowest_val_loss = this_epoch_valid_loss\n",
    "        torch.save(model.state_dict(), f\"./models/{this_filename}\")\n",
    "        epochs_without_new_lowest = 0\n",
    "    else:\n",
    "        epochs_without_new_lowest += 1\n",
    "\n",
    "    if epochs_without_new_lowest >= 25:\n",
    "        break\n",
    "\n",
    "    print(this_epoch_train_loss, this_epoch_valid_loss)\n",
    "    tbwriter.add_scalar('Epoch/Loss/Train', this_epoch_train_loss, i)\n",
    "    tbwriter.add_scalar('Epoch/Loss/Valid', this_epoch_valid_loss, i)\n",
    "    tbwriter.add_scalar('Epoch/lr', optimizer.param_groups[0]['lr'], i)\n",
    "    tbwriter.flush()\n",
    "    \n",
    "    scheduler.step(this_epoch_valid_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\n",
    "    f\"./models/{this_filename}\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_metrics = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_epoch_valid_loss = 0\n",
    "val_preds = []\n",
    "for inputs, labels, masks, meta in val_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        masks = masks.to(device)\n",
    "        meta = meta.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with torch.set_grad_enabled(False):\n",
    "            model = model.eval()\n",
    "            outputs = model(inputs, with_metadata=True, metadata=meta)\n",
    "            loss_0 = criterion(outputs, labels[:, :, 0]) * masks[:, :, 0]\n",
    "            loss_1 = criterion(outputs, labels[:, :, 1]) * masks[:, :, 1]\n",
    "            loss_2 = criterion(outputs, labels[:, :, 2]) * masks[:, :, 2]\n",
    "            loss = (loss_0.sum() + loss_1.sum() + loss_2.sum()) / masks.sum()\n",
    "            this_epoch_valid_loss += loss.detach().cpu().numpy()\n",
    "            val_preds.append(outputs.detach().cpu().numpy())\n",
    "this_epoch_valid_loss /= len(val_loader)\n",
    "val_preds = np.concatenate(val_preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1256669082624071, (4308, 31))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "this_epoch_valid_loss, val_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_metrics['valid_loss'] = this_epoch_valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nodataaug_dataset = AudioDataset(torch.Tensor(train_X),\n",
    "                                       torch.Tensor(train_y),\n",
    "                                       torch.Tensor(train_y_mask),\n",
    "                                       torch.Tensor(train_metadata),\n",
    "                                       None)\n",
    "train_nodataaug_loader = DataLoader(train_nodataaug_dataset, 64, shuffle=False)\n",
    "\n",
    "this_epoch_train_nodataaug_loss = 0\n",
    "train_preds = []\n",
    "for inputs, labels, masks, meta in train_nodataaug_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        masks = masks.to(device)\n",
    "        meta = meta.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with torch.set_grad_enabled(False):\n",
    "            model = model.eval()\n",
    "            outputs = model(inputs, with_metadata=True, metadata=meta)\n",
    "            loss_0 = criterion(outputs, labels[:, :, 0]) * masks[:, :, 0]\n",
    "            loss_1 = criterion(outputs, labels[:, :, 1]) * masks[:, :, 1]\n",
    "            loss_2 = criterion(outputs, labels[:, :, 2]) * masks[:, :, 2]\n",
    "            loss = (loss_0.sum() + loss_1.sum() + loss_2.sum()) / masks.sum()\n",
    "            this_epoch_train_nodataaug_loss += loss.detach().cpu().numpy()\n",
    "            train_preds.append(outputs.detach().cpu().numpy())\n",
    "this_epoch_train_nodataaug_loss /= len(train_nodataaug_loader)\n",
    "train_preds = np.concatenate(train_preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.10229387387352169, (13538, 31))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "this_epoch_train_nodataaug_loss, train_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_metrics['train_loss'] = this_epoch_train_nodataaug_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_cols = ['1_engine', '2_machinery-impact', '3_non-machinery-impact',\n",
    "            '4_powered-saw', '5_alert-signal', '6_music', '7_human-voice', '8_dog',\n",
    "            '1-1_small-sounding-engine', '1-2_medium-sounding-engine',\n",
    "            '1-3_large-sounding-engine', '2-1_rock-drill', '2-2_jackhammer',\n",
    "            '2-3_hoe-ram', '2-4_pile-driver', '3-1_non-machinery-impact',\n",
    "            '4-1_chainsaw', '4-2_small-medium-rotating-saw',\n",
    "            '4-3_large-rotating-saw', '5-1_car-horn', '5-2_car-alarm', '5-3_siren',\n",
    "            '5-4_reverse-beeper', '6-1_stationary-music', '6-2_mobile-music',\n",
    "            '6-3_ice-cream-truck', '7-1_person-or-small-group-talking',\n",
    "            '7-2_person-or-small-group-shouting', '7-3_large-crowd',\n",
    "            '7-4_amplified-speech', '8-1_dog-barking-whining']\n",
    "cols_for_out = [\n",
    "    \"audio_filename\", \"1-1_small-sounding-engine\",\n",
    "    \"1-2_medium-sounding-engine\", \"1-3_large-sounding-engine\",\n",
    "    \"2-1_rock-drill\",\n",
    "    \"2-2_jackhammer\", \"2-3_hoe-ram\", \"2-4_pile-driver\",\n",
    "    \"3-1_non-machinery-impact\",\n",
    "    \"4-1_chainsaw\", \"4-2_small-medium-rotating-saw\",\n",
    "    \"4-3_large-rotating-saw\",\n",
    "    \"5-1_car-horn\", \"5-2_car-alarm\", \"5-3_siren\", \"5-4_reverse-beeper\",\n",
    "    \"6-1_stationary-music\",\n",
    "    \"6-2_mobile-music\", \"6-3_ice-cream-truck\",\n",
    "    \"7-1_person-or-small-group-talking\",\n",
    "    \"7-2_person-or-small-group-shouting\", \"7-3_large-crowd\",\n",
    "    \"7-4_amplified-speech\",\n",
    "    \"8-1_dog-barking-whining\", \"1_engine\", \"2_machinery-impact\",\n",
    "    \"3_non-machinery-impact\", \"4_powered-saw\", \"5_alert-signal\",\n",
    "    \"6_music\", \"7_human-voice\", \"8_dog\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.DataFrame((1 / (1 + np.exp(-val_preds))), columns = our_cols)\n",
    "val_df['audio_filename'] = pd.Series(\n",
    "    sorted(set(metadata['coarse_valid'].index.tolist())),\n",
    "    index=val_df.index)\n",
    "val_df = val_df.loc[:, cols_for_out]\n",
    "val_df = val_df.loc[lambda x: x.audio_filename.isin(\n",
    "    metadata['coarse_valid_gt'].index.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.to_csv('/tmp/val_subm.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./baseline_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import evaluate, macro_averaged_auprc, micro_averaged_auprc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sainatha/dcase2020-task5-urban-sound-tagging-with-context/.env/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3331: DtypeWarning: Columns (47,51,52,53,58,63,67,69) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "df_dict = evaluate(\n",
    "    '/tmp/val_subm.csv',\n",
    "    './data/annotations.csv',\n",
    "    './data/dcase-ust-taxonomy.yaml',\n",
    "    'coarse'\n",
    ")\n",
    "micro_auprc, eval_df = micro_averaged_auprc(df_dict, return_df=True)\n",
    "macro_auprc, class_auprc = macro_averaged_auprc(df_dict, return_classwise=True)\n",
    "thresh_0pt5_idx = (eval_df['threshold'] >= 0.5).to_numpy().nonzero()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8753853200842361, 0.7449134657633407, 0.7057877813504823)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{1: 0.8831959227255064,\n",
       " 2: 0.7143397046005772,\n",
       " 3: 0.5876655847608367,\n",
       " 4: 0.7070967739352572,\n",
       " 5: 0.9526328558115206,\n",
       " 6: 0.569143693796885,\n",
       " 7: 0.9756253876126462,\n",
       " 8: 0.5696078028634965}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "micro_auprc, macro_auprc, eval_df['F'][thresh_0pt5_idx]\n",
    "class_auprc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_metrics['valid_coarse_micro_auprc'] = micro_auprc\n",
    "this_metrics['valid_coarse_macro_auprc'] = macro_auprc\n",
    "this_metrics['valid_coarse_f1'] = eval_df['F'][thresh_0pt5_idx]\n",
    "for k, v in class_auprc.items():\n",
    "    this_metrics[f\"valid_coarse_auprc_class_{k}\"] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./baseline_code/metrics.py:609: UserWarning: Column not found: 1-X_engine-of-uncertain-size\n",
      "  warnings.warn(\"Column not found: \" + f)\n",
      "./baseline_code/metrics.py:609: UserWarning: Column not found: 2-X_other-unknown-impact-machinery\n",
      "  warnings.warn(\"Column not found: \" + f)\n",
      "./baseline_code/metrics.py:609: UserWarning: Column not found: 4-X_other-unknown-powered-saw\n",
      "  warnings.warn(\"Column not found: \" + f)\n",
      "./baseline_code/metrics.py:609: UserWarning: Column not found: 5-X_other-unknown-alert-signal\n",
      "  warnings.warn(\"Column not found: \" + f)\n",
      "./baseline_code/metrics.py:609: UserWarning: Column not found: 6-X_music-from-uncertain-source\n",
      "  warnings.warn(\"Column not found: \" + f)\n",
      "./baseline_code/metrics.py:609: UserWarning: Column not found: 7-X_other-unknown-human-voice\n",
      "  warnings.warn(\"Column not found: \" + f)\n"
     ]
    }
   ],
   "source": [
    "df_dict = evaluate(\n",
    "    '/tmp/val_subm.csv',\n",
    "    './data/annotations.csv',\n",
    "    './data/dcase-ust-taxonomy.yaml',\n",
    "    'fine'\n",
    ")\n",
    "micro_auprc, eval_df = micro_averaged_auprc(df_dict, return_df=True)\n",
    "macro_auprc, class_auprc = macro_averaged_auprc(df_dict, return_classwise=True)\n",
    "thresh_0pt5_idx = (eval_df['threshold'] >= 0.5).to_numpy().nonzero()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7885323826887137, 0.6376440709172527, 0.5592654424040067)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{1: 0.7128869026438804,\n",
       " 2: 0.5596352977611223,\n",
       " 3: 0.6007781323061736,\n",
       " 4: 0.42170684129179037,\n",
       " 5: 0.9168613701464452,\n",
       " 6: 0.3889315037322234,\n",
       " 7: 0.9256520577613885,\n",
       " 8: 0.5747004616949982}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "micro_auprc, macro_auprc, eval_df['F'][thresh_0pt5_idx]\n",
    "class_auprc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_metrics['valid_fine_micro_auprc'] = micro_auprc\n",
    "this_metrics['valid_fine_macro_auprc'] = macro_auprc\n",
    "this_metrics['valid_fine_f1'] = eval_df['F'][thresh_0pt5_idx]\n",
    "for k, v in class_auprc.items():\n",
    "    this_metrics[f\"valid_fine_auprc_class_{k}\"] = v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nodataaug_df = pd.DataFrame((1 / (1 + np.exp(-train_preds))), columns = our_cols)\n",
    "train_nodataaug_df['audio_filename'] = pd.Series(\n",
    "    sorted(set(metadata['coarse_train'].index.tolist())),\n",
    "    index=train_nodataaug_df.index)\n",
    "train_nodataaug_df = train_nodataaug_df.loc[:, cols_for_out]\n",
    "train_nodataaug_df = train_nodataaug_df.loc[lambda x: x.audio_filename.isin(\n",
    "    metadata['coarse_train_gt'].index.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nodataaug_df.to_csv('/tmp/train_nodataaug.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = evaluate(\n",
    "    '/tmp/train_nodataaug.csv',\n",
    "    './data/annotations.csv',\n",
    "    './data/dcase-ust-taxonomy.yaml',\n",
    "    'coarse',\n",
    "    True\n",
    ")\n",
    "micro_auprc, eval_df = micro_averaged_auprc(df_dict, return_df=True)\n",
    "macro_auprc, class_auprc = macro_averaged_auprc(df_dict, return_classwise=True)\n",
    "thresh_0pt5_idx = (eval_df['threshold'] >= 0.5).to_numpy().nonzero()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.930557883214178, 0.7905393637259761, 0.759493670886076)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{1: 0.9416277816816561,\n",
       " 2: 0.6894696037576742,\n",
       " 3: 0.556871196652954,\n",
       " 4: 0.6154809651133181,\n",
       " 5: 0.9662188845698323,\n",
       " 6: 0.6361742424242425,\n",
       " 7: 0.9747492918851879,\n",
       " 8: 0.9437229437229437}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "micro_auprc, macro_auprc, eval_df['F'][thresh_0pt5_idx]\n",
    "class_auprc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_metrics['train_coarse_micro_auprc'] = micro_auprc\n",
    "this_metrics['train_coarse_macro_auprc'] = macro_auprc\n",
    "this_metrics['train_coarse_f1'] = eval_df['F'][thresh_0pt5_idx]\n",
    "for k, v in class_auprc.items():\n",
    "    this_metrics[f\"train_coarse_auprc_class_{k}\"] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = evaluate(\n",
    "    '/tmp/train_nodataaug.csv',\n",
    "    './data/annotations.csv',\n",
    "    './data/dcase-ust-taxonomy.yaml',\n",
    "    'fine',\n",
    "    True\n",
    ")\n",
    "micro_auprc, eval_df = micro_averaged_auprc(df_dict, return_df=True)\n",
    "macro_auprc, class_auprc = macro_averaged_auprc(df_dict, return_classwise=True)\n",
    "thresh_0pt5_idx = (eval_df['threshold'] >= 0.5).to_numpy().nonzero()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.823725953039439, 0.734781246709947, 0.5978835978835979)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{1: 0.6924094223526359,\n",
       " 2: 0.7419054713853576,\n",
       " 3: 0.5447679076835333,\n",
       " 4: 0.4726752316315679,\n",
       " 5: 0.9407072447606555,\n",
       " 6: 0.6373106060606061,\n",
       " 7: 0.8841883755195059,\n",
       " 8: 0.9642857142857142}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "micro_auprc, macro_auprc, eval_df['F'][thresh_0pt5_idx]\n",
    "class_auprc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_metrics['train_fine_micro_auprc'] = micro_auprc\n",
    "this_metrics['train_fine_macro_auprc'] = macro_auprc\n",
    "this_metrics['train_fine_f1'] = eval_df['F'][thresh_0pt5_idx]\n",
    "for k, v in class_auprc.items():\n",
    "    this_metrics[f\"train_fine_auprc_class_{k}\"] = v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_metrics = {\n",
    "    f'hparams/{k}': v\n",
    "    for k, v in this_metrics.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbwriter.add_hparams(hparam_dict=this_hparams, metric_dict=this_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbwriter.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "255.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
